{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "416b0d9a",
   "metadata": {},
   "source": [
    "# Important Note\n",
    "RAM and VRAM measurements are dependent on the computer state, and should only be interpreted relative to each other. In order to obtain RAM and VRAM measurements, perform the following steps:\n",
    "\n",
    "1 - Restart the Kernel\n",
    "\n",
    "2 - Run the \"Loading Required Packages and Helper Functions\" cell\n",
    "\n",
    "3 - Run the \"Loading Data\" cell\n",
    "\n",
    "4 - Run ONLY ONE iteration of the desired method, and read the RAM and VRAM usage reports printed by the cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d6bfc9",
   "metadata": {},
   "source": [
    "# Loading Required Packages and Helper Functions\n",
    "If you would like to use Cuda, set gpu = True. Otherwise set gpu = False. \n",
    "\n",
    "Step 1: Run the preliminary cells to load the packages and data\n",
    "\n",
    "Step 2: Create the HSSVD method.\n",
    "\n",
    "Step 3: Run the execution cells to fit the HSSVD method on the data.\n",
    "\n",
    "# Step 1:\n",
    "Loading Packages and setting benchmark parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64a4ade5-38b2-4f05-8626-7fb74d9fe5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark Parameters\n",
    "gpu, n_replicates = True, 2\n",
    "\n",
    "\n",
    "import os, time, gc, statistics, urllib.request\n",
    "from math import floor\n",
    "import torch, numpy as np, matplotlib, psutil, gpytorch, pynvml, pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "from tqdm import trange, tqdm\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from gpytorch.models import ApproximateGP\n",
    "from gpytorch.variational.nearest_neighbor_variational_strategy import NNVariationalStrategy\n",
    "from gpytorch.models.deep_gps import DeepGPLayer, DeepGP\n",
    "from gpytorch.mlls import DeepApproximateMLL\n",
    "from gpytorch.means import ConstantMean\n",
    "from gpytorch.kernels import ScaleKernel, RBFKernel, InducingPointKernel\n",
    "from gpytorch.distributions import MultivariateNormal\n",
    "\n",
    "\n",
    "max_vram = 0\n",
    "\n",
    "def log_memory():\n",
    "    pynvml.nvmlInit()\n",
    "    h = pynvml.nvmlDeviceGetHandleByIndex(0)\n",
    "    info = pynvml.nvmlDeviceGetMemoryInfo(h)\n",
    "    gpu_used = info.used / 1024**2\n",
    "    torch_alloc = torch.cuda.max_memory_allocated() / 1024**2\n",
    "    sys_used = psutil.virtual_memory().used / 1024**3\n",
    "    print(f\"[GPU] Used: {gpu_used:.2f} MB\\n[PyTorch] Max Allocated: {torch_alloc:.2f} MB\\n[System RAM] Used: {sys_used:.2f} GB\")\n",
    "    return gpu_used, torch_alloc, sys_used\n",
    "\n",
    "def get_mem():\n",
    "    return psutil.Process(os.getpid()).memory_info().rss\n",
    "\n",
    "def vram_usage():\n",
    "    global max_vram\n",
    "    max_vram = max(max_vram, torch.cuda.memory_allocated())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a7e28d-807c-40e4-8868-4146cd1c5911",
   "metadata": {},
   "source": [
    "Loading the data (note: must run the DataGenerator.Rmd file first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fefb002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_x shape: torch.Size([393542, 2])\n",
      "all_y shape: torch.Size([393542])\n"
     ]
    }
   ],
   "source": [
    "import os, numpy as np, pandas as pd, torch\n",
    "\n",
    "gpu = torch.cuda.is_available()\n",
    "smoke_test = 'CI' in os.environ\n",
    "\n",
    "coords_df = pd.read_csv('Data/coordinates.csv')\n",
    "all_x = torch.tensor(coords_df.values, dtype=torch.float32).contiguous()\n",
    "\n",
    "expr_df = pd.read_csv('Data/Mbp.csv')\n",
    "all_y = torch.tensor(expr_df.iloc[:, 0].values, dtype=torch.float32).contiguous()\n",
    "\n",
    "print(\"all_x shape:\", all_x.shape)\n",
    "print(\"all_y shape:\", all_y.shape)\n",
    "\n",
    "import torch, numpy as np\n",
    "\n",
    "def splitter(x_cpu, y_cpu, n_train=80000, n_test=20000, random_state=42, move_to_gpu=True):\n",
    "    assert x_cpu.shape[0] == y_cpu.shape[0]\n",
    "    total = x_cpu.shape[0]\n",
    "    assert n_train + n_test <= total\n",
    "    rng = np.random.default_rng(seed=random_state)\n",
    "    idx = rng.permutation(total)\n",
    "    t, s = n_train, n_train + n_test\n",
    "    train_x = x_cpu[idx[:t]].contiguous()\n",
    "    train_y = y_cpu[idx[:t]].contiguous()\n",
    "    test_x  = x_cpu[idx[t:s]].contiguous()\n",
    "    test_y  = y_cpu[idx[t:s]].contiguous()\n",
    "    if move_to_gpu and torch.cuda.is_available():\n",
    "        train_x, train_y, test_x, test_y = (t.cuda() for t in (train_x, train_y, test_x, test_y))\n",
    "    return train_x, train_y, test_x, test_y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7627436a",
   "metadata": {},
   "source": [
    "# Step 2:\n",
    "Creating the HS-SVD method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16e87fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "def phifunc(m, x):\n",
    "    device = x.device\n",
    "    dtype = x.dtype\n",
    "    n = x.shape[0]\n",
    "    freq = torch.arange(1, m + 1, dtype=dtype, device=device)\n",
    "    sin1 = torch.sin(torch.pi * freq.unsqueeze(1) * x[:, 0].unsqueeze(0))\n",
    "    sin2 = torch.sin(torch.pi * freq.unsqueeze(1) * x[:, 1].unsqueeze(0))\n",
    "    sin1_t = sin1.transpose(0, 1)\n",
    "    sin2_t = sin2.transpose(0, 1)\n",
    "    phi = (sin1_t.unsqueeze(2) * sin2_t.unsqueeze(1)).reshape(n, -1)\n",
    "    return phi\n",
    "\n",
    "\n",
    "def lambdafunc(m, eps, beta):\n",
    "    device = eps.device\n",
    "    dtype = eps.dtype\n",
    "    freq = torch.arange(1, m + 1, dtype=dtype, device=device)\n",
    "    I2 = (freq.unsqueeze(1)**2 + freq.unsqueeze(0)**2)\n",
    "    lam = ((torch.pi**2) * I2 + eps**2)**(-beta)\n",
    "    lam = lam.reshape(-1)\n",
    "    lam = lam / torch.max(lam)\n",
    "    return lam\n",
    "\n",
    "def hssvd_predict_2d(x, y, x_new, init=torch.tensor([0.0, 0.0]), m=30, beta=1, \n",
    "                     train=True, lr=0.01, max_iter=1000, tol=1e-5):\n",
    "    device = x.device\n",
    "    dtype = x.dtype\n",
    "    print(device)\n",
    "    print(dtype)\n",
    "    init = init.to(device=device, dtype=dtype)\n",
    "    print(torch.cuda.memory_allocated() / (1024 ** 2), \"MB allocated\")\n",
    "    n = x.shape[0]\n",
    "    Phi = phifunc(m, x)\n",
    "    MM = Phi.shape[1]\n",
    "    phi_T_phi = Phi.t() @ Phi\n",
    "    phi_T_y = Phi.t() @ y\n",
    "    sum_y2 = torch.sum(y**2)\n",
    "    print(torch.cuda.memory_allocated() / (1024 ** 2), \"MB allocated\")\n",
    "    \n",
    "    def nlik(log_params):\n",
    "        eps = torch.exp(log_params[0])\n",
    "        s2  = torch.exp(log_params[1])\n",
    "        Lambda = lambdafunc(m, eps, beta)\n",
    "        A = s2 * torch.diag(1.0 / Lambda) + phi_T_phi + 1e-10 * torch.eye(MM, device=device, dtype=dtype)\n",
    "        L = torch.linalg.cholesky(A)\n",
    "        sol = torch.cholesky_solve(phi_T_y.unsqueeze(1), L).squeeze(1)\n",
    "        t1 = (sum_y2 - (phi_T_y @ sol)) / s2\n",
    "        logdetA = 2 * torch.sum(torch.log(torch.diag(L)))\n",
    "        t2 = (n - m) * torch.log(s2) + logdetA\n",
    "        t3 = torch.sum(torch.log((Lambda)))\n",
    "        return t1 + t2 + t3\n",
    "    \n",
    "    if train:\n",
    "        print(torch.cuda.memory_allocated() / (1024 ** 2), \"MB allocated\")\n",
    "        log_params = init.clone().detach().requires_grad_(True)\n",
    "        optimizer = optim.Adam([log_params], lr=lr)\n",
    "        prev_loss = None\n",
    "        for iter_ in range(max_iter):\n",
    "            optimizer.zero_grad()\n",
    "            loss = nlik(log_params)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            print(f\"Iter {iter_}: estimate = {log_params.data}, loss = {loss.item():.4f}\", end=\"\\r\")\n",
    "            if prev_loss is not None and torch.abs(loss - prev_loss) < tol*n:\n",
    "                print(f\"\\nConverged after {iter_} iterations\")\n",
    "                break\n",
    "            prev_loss = loss.item()\n",
    "        out = log_params.detach()\n",
    "        print(\"\\nOptimized parameters (log-space):\", out)\n",
    "        print(torch.cuda.memory_allocated() / (1024 ** 2), \"MB allocated\")\n",
    "    else:\n",
    "        out = init\n",
    "    eps  = torch.exp(out[0])\n",
    "    s2   = torch.exp(out[1])\n",
    "    Lambda = lambdafunc(m, eps, beta)\n",
    "    print(torch.cuda.memory_allocated() / (1024 ** 2), \"MB allocated\")\n",
    "    A_final = s2 * torch.diag(1.0 / Lambda) + phi_T_phi + 1e-10 * torch.eye(MM, device=device, dtype=dtype)\n",
    "    L_final = torch.linalg.cholesky(A_final)\n",
    "    sol_final = torch.cholesky_solve(phi_T_y.unsqueeze(1), L_final).squeeze(1)\n",
    "    K_inv_y = (1.0 / s2) * (y - Phi @ sol_final)\n",
    "    print(torch.cuda.memory_allocated() / (1024 ** 2), \"MB allocated\")\n",
    "    Phi_new = phifunc(m, x_new)\n",
    "    y_new = Phi_new @ (torch.diag(Lambda) @ (Phi.t() @ K_inv_y))\n",
    "    log_memory()\n",
    "    return y_new\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7266fd1",
   "metadata": {},
   "source": [
    "# Step 3: Execting the benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0254d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Replicate 1/2 ===\n",
      "cuda:0\n",
      "torch.float32\n",
      "3.5869140625 MB allocated\n",
      "2897.564453125 MB allocated\n",
      "2897.564453125 MB allocated\n",
      "Iter 44: estimate = tensor([ 1.4892, -0.3780], device='cuda:0'), loss = 195257.0000\n",
      "Converged after 44 iterations\n",
      "\n",
      "Optimized parameters (log-space): tensor([ 1.4892, -0.3780], device='cuda:0')\n",
      "2906.00830078125 MB allocated\n",
      "2906.01904296875 MB allocated\n",
      "2955.17333984375 MB allocated\n",
      "[GPU] Used: 14537.05 MB\n",
      "[PyTorch] Max Allocated: 3169.77 MB\n",
      "[System RAM] Used: 35.16 GB\n",
      "Time = 1.5324s, MSE = 0.707767, RAM Used = 316.16MB\n",
      "\n",
      "=== Replicate 2/2 ===\n",
      "cuda:0\n",
      "torch.float32\n",
      "20.1533203125 MB allocated\n",
      "2906.16357421875 MB allocated\n",
      "2906.16357421875 MB allocated\n",
      "Iter 44: estimate = tensor([ 1.4747, -0.3776], device='cuda:0'), loss = 195444.7812\n",
      "Converged after 44 iterations\n",
      "\n",
      "Optimized parameters (log-space): tensor([ 1.4747, -0.3776], device='cuda:0')\n",
      "2906.166015625 MB allocated\n",
      "2906.1767578125 MB allocated\n",
      "2955.015625 MB allocated\n",
      "[GPU] Used: 14519.54 MB\n",
      "[PyTorch] Max Allocated: 3169.77 MB\n",
      "[System RAM] Used: 35.17 GB\n",
      "Time = 0.6823s, MSE = 0.711889, RAM Used = 0.18MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time (s)</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RAM Used (MB)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.532364</td>\n",
       "      <td>0.707767</td>\n",
       "      <td>316.160156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.682261</td>\n",
       "      <td>0.711889</td>\n",
       "      <td>0.183594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time (s)       MSE  RAM Used (MB)\n",
       "0  1.532364  0.707767     316.160156\n",
       "1  0.682261  0.711889       0.183594"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "import psutil\n",
    "import pandas as pd\n",
    "init=torch.tensor([0.0,0.0],dtype=torch.float32)\n",
    "m=50\n",
    "beta=1.5\n",
    "lr=0.1\n",
    "num_repeats=n_replicates\n",
    "results=[]\n",
    "process=psutil.Process()\n",
    "for i in range(num_repeats):\n",
    "    print(f\"\\n=== Replicate {i+1}/{num_repeats} ===\")\n",
    "    train_x,train_y,test_x,test_y=splitter(all_x,all_y,n_train=300000,n_test=20000,random_state=i, move_to_gpu=gpu)\n",
    "    if test_y.is_cuda:test_y=test_y.cpu()\n",
    "    ram_before=process.memory_info().rss/(1024**2)\n",
    "    start_time=time.time()\n",
    "    y_pred=hssvd_predict_2d(train_x,train_y,test_x,init=init,m=m,beta=beta,train=True,lr=lr)\n",
    "    elapsed_time=time.time()-start_time\n",
    "    if y_pred.is_cuda:y_pred=y_pred.cpu()\n",
    "    if test_y.is_cuda:test_y=test_y.cpu()\n",
    "    mse=torch.mean((y_pred-test_y)**2).item()\n",
    "    ram_after=process.memory_info().rss/(1024**2)\n",
    "    ram_used=ram_after-ram_before\n",
    "    results.append((elapsed_time,mse,ram_used))\n",
    "    print(f\"Time = {elapsed_time:.4f}s, MSE = {mse:.6f}, RAM Used = {ram_used:.2f}MB\")\n",
    "df=pd.DataFrame(results,columns=[\"Time (s)\",\"MSE\",\"RAM Used (MB)\"])\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc90ebd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: Mean = 1.1073s, SD = 0.6011s\n",
      "MSE: Mean = 0.709828, SD = 0.002914\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "results_array = np.array(results)\n",
    "\n",
    "time_values = results_array[:, 0]\n",
    "mse_values = results_array[:, 1]\n",
    "\n",
    "\n",
    "time_mean = np.mean(time_values)\n",
    "time_sd = np.std(time_values, ddof=1)\n",
    "\n",
    "mse_mean = np.mean(mse_values)\n",
    "mse_sd = np.std(mse_values, ddof=1)\n",
    "\n",
    "print(f\"Time: Mean = {time_mean:.4f}s, SD = {time_sd:.4f}s\")\n",
    "print(f\"MSE: Mean = {mse_mean:.6f}, SD = {mse_sd:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb54de8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7fbdd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (scaleGP)",
   "language": "python",
   "name": "scalegp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
