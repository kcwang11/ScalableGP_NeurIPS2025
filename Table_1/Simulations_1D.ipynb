{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7511799-a297-4192-8eab-f89cdc78dd2c",
   "metadata": {},
   "source": [
    "# Important Note\n",
    "RAM and VRAM measurements are dependent on the computer state, and should only be interpreted relative to each other. In order to obtain RAM and VRAM measurements, perform the following steps:\n",
    "\n",
    "1 - Restart the Kernel\n",
    "\n",
    "2 - Run the \"Loading Required Packages and Helper Functions\" cell\n",
    "\n",
    "3 - Run the \"Loading Data\" cell\n",
    "\n",
    "4 - Run ONLY ONE iteration of the desired method, and read the RAM and VRAM usage reports printed by the cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531dca75-5931-4d1c-a9c7-f4b266b6ec42",
   "metadata": {},
   "source": [
    "# Loading Required Packages and Helper Functions\n",
    "If you would like to use Cuda, set gpu = True. Otherwise set gpu = False. \n",
    "\n",
    "Step 1: Run the following cell to import the required packages and helper functions. Set the number of replicates desired.\n",
    "\n",
    "Step 2: Load the Data\n",
    "\n",
    "Step 3: Execute the cells under the method you wish to replicate.\n",
    "\n",
    "# Step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06e0d00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e07126f-2559-4249-9221-117c4c53ecc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu = True\n",
    "n_replicates = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6605e5-f791-44f8-ada3-9efb2237ed1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "import gc\n",
    "import statistics\n",
    "import numpy as np\n",
    "\n",
    "from gpytorch.models import ApproximateGP\n",
    "from gpytorch.variational.nearest_neighbor_variational_strategy import NNVariationalStrategy\n",
    "# Make plots inline\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import psutil\n",
    "def get_mem():\n",
    "    process = psutil.Process(os.getpid())\n",
    "    mem_info = process.memory_info()\n",
    "    return mem_info.rss\n",
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "import gc\n",
    "import tqdm\n",
    "import gpytorch\n",
    "import tqdm\n",
    "import urllib.request\n",
    "import os\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "from math import floor\n",
    "from gpytorch.models.deep_gps import DeepGPLayer, DeepGP\n",
    "from gpytorch.mlls import DeepApproximateMLL\n",
    "\n",
    "from gpytorch.means import ConstantMean\n",
    "from gpytorch.kernels import ScaleKernel, RBFKernel, InducingPointKernel\n",
    "from gpytorch.distributions import MultivariateNormal\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from gpytorch.models.deep_gps import DeepGPLayer, DeepGP\n",
    "from gpytorch.mlls import DeepApproximateMLL\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from gpytorch.models import ApproximateGP\n",
    "from gpytorch.variational.nearest_neighbor_variational_strategy import NNVariationalStrategy\n",
    "from gpytorch.models import ApproximateGP\n",
    "from gpytorch.variational import CholeskyVariationalDistribution\n",
    "from gpytorch.variational import VariationalStrategy\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import gpytorch\n",
    "import pynvml\n",
    "import psutil\n",
    "import statistics\n",
    "from tqdm import trange, tqdm\n",
    "\n",
    "import torch\n",
    "import pynvml\n",
    "import psutil\n",
    "\n",
    "def log_memory():\n",
    "    pynvml.nvmlInit()\n",
    "    handle = pynvml.nvmlDeviceGetHandleByIndex(0)\n",
    "    meminfo = pynvml.nvmlDeviceGetMemoryInfo(handle)\n",
    "    max_allocated = torch.cuda.max_memory_allocated() / 1024**2  # MB\n",
    "    max_reserved = torch.cuda.max_memory_reserved() / 1024**2    # MB\n",
    "    gpu_used = meminfo.used / 1024**2                            # MB\n",
    "    sys_used = psutil.virtual_memory().used / 1024**3            # GB\n",
    "    print(f\"[PyTorch] Max Allocated: {max_allocated:.2f} MB | Max Reserved: {max_reserved:.2f} MB\")\n",
    "    print(f\"[GPU VRAM] Used (nvidia-smi): {gpu_used:.2f} MB | [System RAM]: {sys_used:.2f} GB\")\n",
    "    return max_allocated, max_reserved, gpu_used, sys_used\n",
    "\n",
    "\n",
    "max_vram = 0\n",
    "max_ram = 0\n",
    "def get_mem():\n",
    "    process = psutil.Process(os.getpid())\n",
    "    mem_info = process.memory_info()\n",
    "    return mem_info.rss/(1024**2)\n",
    "\n",
    "max_vram = 0\n",
    "def vram_usage():\n",
    "    global max_vram\n",
    "    if gpu:\n",
    "        max_vram = max(max_vram, torch.cuda.memory_allocated())\n",
    "\n",
    "\n",
    "print(\"GPU availability: \", torch.cuda.is_available())\n",
    "print(psutil.virtual_memory().used / (1024 ** 2))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a7e28d-807c-40e4-8868-4146cd1c5911",
   "metadata": {},
   "source": [
    "# Loading Data\n",
    "Step 2: Load the data (note: must run the DataGenerator.Rmd file first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d29fd88-72ae-43bf-9292-e9f77f51d552",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "x = pd.read_csv('Data/x_100k.csv', header=None).values.squeeze()\n",
    "y = pd.read_csv('Data/y_100k.csv', header=None).values.squeeze()\n",
    "all_x = torch.tensor(x, dtype=torch.float32).unsqueeze(1)\n",
    "all_y = torch.tensor(y, dtype=torch.float32)\n",
    "all_x = all_x.contiguous()\n",
    "all_y = all_y.contiguous()\n",
    "print(\"all_x shape:\", all_x.shape)\n",
    "print(\"all_y shape:\", all_y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e74326",
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitter(x_cpu, y_cpu, n_train=80000, n_test=20000, random_state=42, move_to_gpu=True):\n",
    "    assert x_cpu.shape[0] == y_cpu.shape[0], \"Mismatch in number of samples\"\n",
    "    total_samples = x_cpu.shape[0]\n",
    "    assert n_train + n_test <= total_samples, \"Not enough samples to split\"\n",
    "    rng = np.random.default_rng(seed=random_state)\n",
    "    indices = rng.permutation(total_samples)\n",
    "    train_idx = indices[:n_train]\n",
    "    test_idx  = indices[n_train:n_train + n_test]\n",
    "    train_x = x_cpu[train_idx].contiguous()\n",
    "    train_y = y_cpu[train_idx].contiguous()\n",
    "    test_x  = x_cpu[test_idx].contiguous()\n",
    "    test_y  = y_cpu[test_idx].contiguous()\n",
    "    if move_to_gpu and torch.cuda.is_available():\n",
    "        train_x = train_x.cuda()\n",
    "        train_y = train_y.cuda()\n",
    "        test_x = test_x.cuda()\n",
    "        test_y = test_y.cuda()\n",
    "    return train_x, train_y, test_x, test_y\n",
    "\n",
    "train_x, train_y, test_x, test_y = splitter(all_x, all_y, n_train=80000, n_test=20000)\n",
    "print(train_x.shape, train_y.shape)\n",
    "print(test_x.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786b6082",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6ca619-2934-42e4-8d62-9c5ae1a6c9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################################################################\n",
    "####################################################################################################################################\n",
    "####################################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2e5420",
   "metadata": {},
   "source": [
    "# Simulations\n",
    "Step 3: Execute the simulations to be reproduced. If all simulations are run, there is a summarizer at the end. Otherwise, the relevant statistics are printed at the end of each method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b955df80-1c9d-4055-8e5e-3ea753501029",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# SKI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "594b5818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Replicate 1/11 ===\n",
      "Rep 1: MSE=0.2989, Time=9.30s, RAM before=0.0MB, peak=1095.1MB (Î”=1095.1MB), VRAM peak=5949.0MB\n",
      "\n",
      "=== Replicate 2/11 ===\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 56\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     55\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 56\u001b[0m peak_ram \u001b[38;5;241m=\u001b[39m \u001b[43mmemory_usage\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_usage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\n\u001b[0;32m     61\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[0;32m     63\u001b[0m vram_peak \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mmax_memory_allocated() \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1024\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\memory_profiler.py:379\u001b[0m, in \u001b[0;36mmemory_usage\u001b[1;34m(proc, interval, timeout, timestamps, include_children, multiprocess, max_usage, retval, stream, backend, max_iterations)\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[38;5;66;03m# When there is an exception in the \"proc\" - the (spawned) monitoring processes don't get killed.\u001b[39;00m\n\u001b[0;32m    377\u001b[0m \u001b[38;5;66;03m# Therefore, the whole process hangs indefinitely. Here, we are ensuring that the process gets killed!\u001b[39;00m\n\u001b[0;32m    378\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 379\u001b[0m     returned \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    380\u001b[0m     parent_conn\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# finish timing\u001b[39;00m\n\u001b[0;32m    381\u001b[0m     ret \u001b[38;5;241m=\u001b[39m parent_conn\u001b[38;5;241m.\u001b[39mrecv()\n",
      "Cell \u001b[1;32mIn[7], line 51\u001b[0m, in \u001b[0;36mtrain_fn\u001b[1;34m()\u001b[0m\n\u001b[0;32m     49\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     50\u001b[0m output \u001b[38;5;241m=\u001b[39m model(train_x)\n\u001b[1;32m---> 51\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[43mmll\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     53\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\scaleGP\\lib\\site-packages\\gpytorch\\module.py:31\u001b[0m, in \u001b[0;36mModule.__call__\u001b[1;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Tensor, Distribution, LinearOperator]:\n\u001b[1;32m---> 31\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(\u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m     33\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [_validate_module_outputs(output) \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m outputs]\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\scaleGP\\lib\\site-packages\\gpytorch\\mlls\\exact_marginal_log_likelihood.py:82\u001b[0m, in \u001b[0;36mExactMarginalLogLikelihood.forward\u001b[1;34m(self, function_dist, target, *params, **kwargs)\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaN observation policy \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfill\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not supported by ExactMarginalLogLikelihood!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     81\u001b[0m \u001b[38;5;66;03m# Get the log prob of the marginal distribution\u001b[39;00m\n\u001b[1;32m---> 82\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     83\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_other_terms(res, params)\n\u001b[0;32m     85\u001b[0m \u001b[38;5;66;03m# Scale by the amount of data we have\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\scaleGP\\lib\\site-packages\\gpytorch\\distributions\\multivariate_normal.py:192\u001b[0m, in \u001b[0;36mMultivariateNormal.log_prob\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m    185\u001b[0m         covar \u001b[38;5;241m=\u001b[39m covar\u001b[38;5;241m.\u001b[39mrepeat(\n\u001b[0;32m    186\u001b[0m             \u001b[38;5;241m*\u001b[39m(diff_size \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m covar_size \u001b[38;5;28;01mfor\u001b[39;00m diff_size, covar_size \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(diff\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], padded_batch_shape)),\n\u001b[0;32m    187\u001b[0m             \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m    188\u001b[0m             \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m    189\u001b[0m         )\n\u001b[0;32m    191\u001b[0m \u001b[38;5;66;03m# Get log determininant and first part of quadratic form\u001b[39;00m\n\u001b[1;32m--> 192\u001b[0m covar \u001b[38;5;241m=\u001b[39m \u001b[43mcovar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_kernel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    193\u001b[0m inv_quad, logdet \u001b[38;5;241m=\u001b[39m covar\u001b[38;5;241m.\u001b[39minv_quad_logdet(inv_quad_rhs\u001b[38;5;241m=\u001b[39mdiff\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), logdet\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    195\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28msum\u001b[39m([inv_quad, logdet, diff\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m math\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m math\u001b[38;5;241m.\u001b[39mpi)])\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\scaleGP\\lib\\site-packages\\linear_operator\\operators\\added_diag_linear_operator.py:209\u001b[0m, in \u001b[0;36mAddedDiagLinearOperator.evaluate_kernel\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate_kernel\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 209\u001b[0m     added_diag_linear_op \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepresentation_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrepresentation())\n\u001b[0;32m    210\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m added_diag_linear_op\u001b[38;5;241m.\u001b[39m_linear_op \u001b[38;5;241m+\u001b[39m added_diag_linear_op\u001b[38;5;241m.\u001b[39m_diag_tensor\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\scaleGP\\lib\\site-packages\\linear_operator\\operators\\_linear_operator.py:2072\u001b[0m, in \u001b[0;36mLinearOperator.representation_tree\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2062\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrepresentation_tree\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LinearOperatorRepresentationTree:\n\u001b[0;32m   2063\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2064\u001b[0m \u001b[38;5;124;03m    Returns a\u001b[39;00m\n\u001b[0;32m   2065\u001b[0m \u001b[38;5;124;03m    :obj:`linear_operator.operators.LinearOperatorRepresentationTree` tree\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2070\u001b[0m \u001b[38;5;124;03m    including all subobjects. This is used internally.\u001b[39;00m\n\u001b[0;32m   2071\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2072\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mLinearOperatorRepresentationTree\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\scaleGP\\lib\\site-packages\\linear_operator\\operators\\linear_operator_representation_tree.py:15\u001b[0m, in \u001b[0;36mLinearOperatorRepresentationTree.__init__\u001b[1;34m(self, linear_op)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(linear_op\u001b[38;5;241m.\u001b[39m_args, linear_op\u001b[38;5;241m.\u001b[39m_differentiable_kwargs\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrepresentation\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(arg\u001b[38;5;241m.\u001b[39mrepresentation):  \u001b[38;5;66;03m# Is it a lazy tensor?\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m         representation_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[43marg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepresentation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     16\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren\u001b[38;5;241m.\u001b[39mappend((\u001b[38;5;28mslice\u001b[39m(counter, counter \u001b[38;5;241m+\u001b[39m representation_size, \u001b[38;5;28;01mNone\u001b[39;00m), arg\u001b[38;5;241m.\u001b[39mrepresentation_tree()))\n\u001b[0;32m     17\u001b[0m         counter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m representation_size\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\scaleGP\\lib\\site-packages\\gpytorch\\lazy\\lazy_evaluated_kernel_tensor.py:397\u001b[0m, in \u001b[0;36mLazyEvaluatedKernelTensor.representation\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    393\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrepresentation()\n\u001b[0;32m    394\u001b[0m \u001b[38;5;66;03m# Otherwise, we'll evaluate the kernel (or at least its LinearOperator representation) and use its\u001b[39;00m\n\u001b[0;32m    395\u001b[0m \u001b[38;5;66;03m# representation\u001b[39;00m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_kernel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mrepresentation()\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\scaleGP\\lib\\site-packages\\gpytorch\\utils\\memoize.py:59\u001b[0m, in \u001b[0;36m_cached.<locals>.g\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     57\u001b[0m kwargs_pkl \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mdumps(kwargs)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_in_cache(\u001b[38;5;28mself\u001b[39m, cache_name, \u001b[38;5;241m*\u001b[39margs, kwargs_pkl\u001b[38;5;241m=\u001b[39mkwargs_pkl):\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _add_to_cache(\u001b[38;5;28mself\u001b[39m, cache_name, method(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs), \u001b[38;5;241m*\u001b[39margs, kwargs_pkl\u001b[38;5;241m=\u001b[39mkwargs_pkl)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _get_from_cache(\u001b[38;5;28mself\u001b[39m, cache_name, \u001b[38;5;241m*\u001b[39margs, kwargs_pkl\u001b[38;5;241m=\u001b[39mkwargs_pkl)\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\scaleGP\\lib\\site-packages\\gpytorch\\lazy\\lazy_evaluated_kernel_tensor.py:25\u001b[0m, in \u001b[0;36mrecall_grad_state.<locals>.wrapped\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(method)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_grad_enabled):\n\u001b[1;32m---> 25\u001b[0m         output \u001b[38;5;241m=\u001b[39m method(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\scaleGP\\lib\\site-packages\\gpytorch\\lazy\\lazy_evaluated_kernel_tensor.py:355\u001b[0m, in \u001b[0;36mLazyEvaluatedKernelTensor.evaluate_kernel\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    353\u001b[0m     temp_active_dims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel\u001b[38;5;241m.\u001b[39mactive_dims\n\u001b[0;32m    354\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel\u001b[38;5;241m.\u001b[39mactive_dims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 355\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel(\n\u001b[0;32m    356\u001b[0m         x1,\n\u001b[0;32m    357\u001b[0m         x2,\n\u001b[0;32m    358\u001b[0m         diag\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    359\u001b[0m         last_dim_is_batch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_dim_is_batch,\n\u001b[0;32m    360\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams,\n\u001b[0;32m    361\u001b[0m     )\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel\u001b[38;5;241m.\u001b[39mactive_dims \u001b[38;5;241m=\u001b[39m temp_active_dims\n\u001b[0;32m    364\u001b[0m \u001b[38;5;66;03m# Check the size of the output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\scaleGP\\lib\\site-packages\\gpytorch\\kernels\\kernel.py:539\u001b[0m, in \u001b[0;36mKernel.__call__\u001b[1;34m(self, x1, x2, diag, last_dim_is_batch, **params)\u001b[0m\n\u001b[0;32m    536\u001b[0m     res \u001b[38;5;241m=\u001b[39m LazyEvaluatedKernelTensor(x1_, x2_, kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, last_dim_is_batch\u001b[38;5;241m=\u001b[39mlast_dim_is_batch, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    538\u001b[0m     res \u001b[38;5;241m=\u001b[39m to_linear_operator(\n\u001b[1;32m--> 539\u001b[0m         \u001b[38;5;28msuper\u001b[39m(Kernel, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(x1_, x2_, last_dim_is_batch\u001b[38;5;241m=\u001b[39mlast_dim_is_batch, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m    540\u001b[0m     )\n\u001b[0;32m    541\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\scaleGP\\lib\\site-packages\\gpytorch\\module.py:31\u001b[0m, in \u001b[0;36mModule.__call__\u001b[1;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Tensor, Distribution, LinearOperator]:\n\u001b[1;32m---> 31\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(\u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m     33\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [_validate_module_outputs(output) \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m outputs]\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\scaleGP\\lib\\site-packages\\gpytorch\\kernels\\scale_kernel.py:109\u001b[0m, in \u001b[0;36mScaleKernel.forward\u001b[1;34m(self, x1, x2, last_dim_is_batch, diag, **params)\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x1, x2, last_dim_is_batch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, diag\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams):\n\u001b[1;32m--> 109\u001b[0m     orig_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_kernel\u001b[38;5;241m.\u001b[39mforward(x1, x2, diag\u001b[38;5;241m=\u001b[39mdiag, last_dim_is_batch\u001b[38;5;241m=\u001b[39mlast_dim_is_batch, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m    110\u001b[0m     outputscales \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutputscale\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m last_dim_is_batch:\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\scaleGP\\lib\\site-packages\\gpytorch\\kernels\\grid_interpolation_kernel.py:155\u001b[0m, in \u001b[0;36mGridInterpolationKernel.forward\u001b[1;34m(self, x1, x2, diag, last_dim_is_batch, **params)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    154\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([x1\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_dims), x2\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_dims)])\n\u001b[1;32m--> 155\u001b[0m x_maxs \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    156\u001b[0m x_mins \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mmin(\u001b[38;5;241m0\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m    158\u001b[0m \u001b[38;5;66;03m# We need to update the grid if\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;66;03m# 1) it hasn't ever been initialized, or\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;66;03m# 2) if any of the grid points are \"out of bounds\"\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tqdm, time, gc\n",
    "import torch, gpytorch\n",
    "from memory_profiler import memory_usage\n",
    "\n",
    "\n",
    "class GPRegressionModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super().__init__(train_x, train_y, likelihood)\n",
    "        grid_size = gpytorch.utils.grid.choose_grid_size(train_x, 1.0 / 25.0)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(\n",
    "            gpytorch.kernels.GridInterpolationKernel(\n",
    "                gpytorch.kernels.MaternKernel(nu=1.5, ard_num_dims=1),\n",
    "                grid_size=grid_size, num_dims=1\n",
    "            )\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return gpytorch.distributions.MultivariateNormal(\n",
    "            self.mean_module(x),\n",
    "            self.covar_module(x)\n",
    "        )\n",
    "\n",
    "n_replicates = 11\n",
    "training_iterations = 32\n",
    "n_train, n_test = 400_000, 20_000\n",
    "random_state = 42\n",
    "mse_l_ski, time_l_ski = [], []\n",
    "\n",
    "for rep in range(n_replicates):\n",
    "    print(f\"\\n=== Replicate {rep + 1}/{n_replicates} ===\")\n",
    "    train_x, train_y, test_x, test_y = splitter(\n",
    "        all_x, all_y,\n",
    "        n_train=n_train, n_test=n_test,\n",
    "        random_state=random_state + rep,\n",
    "        move_to_gpu=torch.cuda.is_available()\n",
    "    )\n",
    "    ram_before = get_mem() / (1024**2)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "    likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "    model = GPRegressionModel(train_x, train_y, likelihood)\n",
    "    model.train(); likelihood.train()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "    if torch.cuda.is_available():\n",
    "        mll = mll.cuda()\n",
    "    def train_fn():\n",
    "        for _ in range(training_iterations):\n",
    "            optimizer.zero_grad()\n",
    "            output = model(train_x)\n",
    "            loss = -mll(output, train_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        return None\n",
    "    start_time = time.time()\n",
    "    peak_ram = memory_usage(\n",
    "        (train_fn,),\n",
    "        max_usage=True,\n",
    "        retval=False,\n",
    "        interval=0.01\n",
    "    )\n",
    "    elapsed = time.time() - start_time\n",
    "    vram_peak = torch.cuda.max_memory_allocated() / (1024**2) if torch.cuda.is_available() else None\n",
    "    ram_delta = peak_ram - ram_before\n",
    "    model.eval(); likelihood.eval()\n",
    "    with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "        pred = likelihood(model(test_x)).mean.cpu()\n",
    "    mse = torch.mean((pred - test_y.cpu()) ** 2).item()\n",
    "    mse_l_ski.append(mse)\n",
    "    time_l_ski.append(elapsed)\n",
    "    print(\n",
    "        f\"Rep {rep+1}: MSE={mse:.4f}, Time={elapsed:.2f}s, \"\n",
    "        f\"RAM before={ram_before:.1f}MB, peak={peak_ram:.1f}MB (Î”={ram_delta:.1f}MB)\"\n",
    "        + (f\", VRAM peak={vram_peak:.1f}MB\" if vram_peak is not None else \"\")\n",
    "    )\n",
    "    del model, likelihood\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "baa31965",
   "metadata": {},
   "outputs": [
    {
     "ename": "StatisticsError",
     "evalue": "mean requires at least one data point",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStatisticsError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mstatistics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmse_l_ski\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(statistics\u001b[38;5;241m.\u001b[39mstdev(mse_l_ski[\u001b[38;5;241m1\u001b[39m:]))\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(statistics\u001b[38;5;241m.\u001b[39mmean(time_l_ski[\u001b[38;5;241m1\u001b[39m:]))\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\scaleGP\\lib\\statistics.py:315\u001b[0m, in \u001b[0;36mmean\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    313\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(data)\n\u001b[0;32m    314\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 315\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StatisticsError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean requires at least one data point\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    316\u001b[0m T, total, count \u001b[38;5;241m=\u001b[39m _sum(data)\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m count \u001b[38;5;241m==\u001b[39m n\n",
      "\u001b[1;31mStatisticsError\u001b[0m: mean requires at least one data point"
     ]
    }
   ],
   "source": [
    "print(statistics.mean(mse_l_ski[1:]))\n",
    "print(statistics.stdev(mse_l_ski[1:]))\n",
    "\n",
    "print(statistics.mean(time_l_ski[1:]))\n",
    "print(statistics.stdev(time_l_ski[1:]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfad5eb3-9eb7-44ba-a7bd-c680b3716264",
   "metadata": {},
   "source": [
    "# Sparse GPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10e5399d-22be-42e9-ad0d-4db2b746f637",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "max_vram = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d229e74-5c6b-401b-8a77-a2361bf99247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Replicate 1/11 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [00:10<00:00, 12.34it/s, loss=0.831]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PyTorch] Max Allocated: 2186.85 MB | Max Reserved: 2228.00 MB\n",
      "[GPU VRAM] Used (nvidia-smi): 3819.63 MB | [System RAM]: 21.01 GB\n",
      "Rep 1: MSE=0.2967, Time=10.13s, VRAM=2186.85MB, RAM diff=10.81MB\n",
      "\n",
      "=== Replicate 2/11 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 2:  15%|â–ˆâ–Œ        | 19/125 [00:01<00:08, 12.55it/s, loss=1.11]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 95\u001b[0m\n\u001b[0;32m     93\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     94\u001b[0m output \u001b[38;5;241m=\u001b[39m model(train_x)\n\u001b[1;32m---> 95\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[43mmll\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     97\u001b[0m iterator\u001b[38;5;241m.\u001b[39mset_postfix(loss\u001b[38;5;241m=\u001b[39mloss\u001b[38;5;241m.\u001b[39mitem())  \u001b[38;5;66;03m# <-- Add this line\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\scaleGP\\lib\\site-packages\\gpytorch\\module.py:31\u001b[0m, in \u001b[0;36mModule.__call__\u001b[1;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Tensor, Distribution, LinearOperator]:\n\u001b[1;32m---> 31\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(\u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m     33\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [_validate_module_outputs(output) \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m outputs]\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\scaleGP\\lib\\site-packages\\gpytorch\\mlls\\exact_marginal_log_likelihood.py:82\u001b[0m, in \u001b[0;36mExactMarginalLogLikelihood.forward\u001b[1;34m(self, function_dist, target, *params, **kwargs)\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaN observation policy \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfill\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not supported by ExactMarginalLogLikelihood!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     81\u001b[0m \u001b[38;5;66;03m# Get the log prob of the marginal distribution\u001b[39;00m\n\u001b[1;32m---> 82\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     83\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_other_terms(res, params)\n\u001b[0;32m     85\u001b[0m \u001b[38;5;66;03m# Scale by the amount of data we have\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\scaleGP\\lib\\site-packages\\gpytorch\\distributions\\multivariate_normal.py:193\u001b[0m, in \u001b[0;36mMultivariateNormal.log_prob\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;66;03m# Get log determininant and first part of quadratic form\u001b[39;00m\n\u001b[0;32m    192\u001b[0m covar \u001b[38;5;241m=\u001b[39m covar\u001b[38;5;241m.\u001b[39mevaluate_kernel()\n\u001b[1;32m--> 193\u001b[0m inv_quad, logdet \u001b[38;5;241m=\u001b[39m \u001b[43mcovar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minv_quad_logdet\u001b[49m\u001b[43m(\u001b[49m\u001b[43minv_quad_rhs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdiff\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogdet\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    195\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28msum\u001b[39m([inv_quad, logdet, diff\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m math\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m math\u001b[38;5;241m.\u001b[39mpi)])\n\u001b[0;32m    196\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\scaleGP\\lib\\site-packages\\linear_operator\\operators\\low_rank_root_added_diag_linear_operator.py:149\u001b[0m, in \u001b[0;36mLowRankRootAddedDiagLinearOperator.inv_quad_logdet\u001b[1;34m(self, inv_quad_rhs, logdet, reduce_inv_quad)\u001b[0m\n\u001b[0;32m    146\u001b[0m inv_quad_term, logdet_term \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inv_quad_rhs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 149\u001b[0m     self_inv_rhs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_solve\u001b[49m\u001b[43m(\u001b[49m\u001b[43minv_quad_rhs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    150\u001b[0m     inv_quad_term \u001b[38;5;241m=\u001b[39m (inv_quad_rhs \u001b[38;5;241m*\u001b[39m self_inv_rhs)\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    151\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m reduce_inv_quad:\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\scaleGP\\lib\\site-packages\\linear_operator\\operators\\low_rank_root_added_diag_linear_operator.py:76\u001b[0m, in \u001b[0;36mLowRankRootAddedDiagLinearOperator._solve\u001b[1;34m(self, rhs, preconditioner, num_tridiag)\u001b[0m\n\u001b[0;32m     74\u001b[0m U \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_linear_op\u001b[38;5;241m.\u001b[39mroot\n\u001b[0;32m     75\u001b[0m V \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_linear_op\u001b[38;5;241m.\u001b[39mroot\u001b[38;5;241m.\u001b[39mmT\n\u001b[1;32m---> 76\u001b[0m chol_cap_mat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchol_cap_mat\u001b[49m\n\u001b[0;32m     78\u001b[0m res \u001b[38;5;241m=\u001b[39m V\u001b[38;5;241m.\u001b[39mmatmul(A_inv\u001b[38;5;241m.\u001b[39mmatmul(rhs))\n\u001b[0;32m     79\u001b[0m res \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcholesky_solve(res, chol_cap_mat)\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\scaleGP\\lib\\site-packages\\linear_operator\\utils\\memoize.py:59\u001b[0m, in \u001b[0;36m_cached.<locals>.g\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     57\u001b[0m kwargs_pkl \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mdumps(kwargs)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_in_cache(\u001b[38;5;28mself\u001b[39m, cache_name, \u001b[38;5;241m*\u001b[39margs, kwargs_pkl\u001b[38;5;241m=\u001b[39mkwargs_pkl):\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _add_to_cache(\u001b[38;5;28mself\u001b[39m, cache_name, method(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs), \u001b[38;5;241m*\u001b[39margs, kwargs_pkl\u001b[38;5;241m=\u001b[39mkwargs_pkl)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _get_from_cache(\u001b[38;5;28mself\u001b[39m, cache_name, \u001b[38;5;241m*\u001b[39margs, kwargs_pkl\u001b[38;5;241m=\u001b[39mkwargs_pkl)\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\scaleGP\\lib\\site-packages\\linear_operator\\operators\\low_rank_root_added_diag_linear_operator.py:44\u001b[0m, in \u001b[0;36mLowRankRootAddedDiagLinearOperator.chol_cap_mat\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     41\u001b[0m C \u001b[38;5;241m=\u001b[39m ConstantDiagLinearOperator(torch\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;241m*\u001b[39mV\u001b[38;5;241m.\u001b[39mbatch_shape, \u001b[38;5;241m1\u001b[39m, device\u001b[38;5;241m=\u001b[39mV\u001b[38;5;241m.\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39mV\u001b[38;5;241m.\u001b[39mdtype), V\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m])\n\u001b[0;32m     43\u001b[0m cap_mat \u001b[38;5;241m=\u001b[39m to_dense(C \u001b[38;5;241m+\u001b[39m V\u001b[38;5;241m.\u001b[39mmatmul(A_inv\u001b[38;5;241m.\u001b[39mmatmul(U)))\n\u001b[1;32m---> 44\u001b[0m chol_cap_mat \u001b[38;5;241m=\u001b[39m \u001b[43mpsd_safe_cholesky\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcap_mat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m chol_cap_mat\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\scaleGP\\lib\\site-packages\\linear_operator\\utils\\cholesky.py:65\u001b[0m, in \u001b[0;36mpsd_safe_cholesky\u001b[1;34m(A, upper, out, jitter, max_tries)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpsd_safe_cholesky\u001b[39m(A, upper\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, jitter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, max_tries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     51\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute the Cholesky decomposition of A. If A is only p.s.d, add a small jitter to the diagonal.\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;124;03m        :attr:`A` (Tensor):\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;124;03m            Number of attempts (with successively increasing jitter) to make before raising an error.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m     L \u001b[38;5;241m=\u001b[39m \u001b[43m_psd_safe_cholesky\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjitter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjitter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_tries\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m upper:\n\u001b[0;32m     67\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\scaleGP\\lib\\site-packages\\linear_operator\\utils\\cholesky.py:21\u001b[0m, in \u001b[0;36m_psd_safe_cholesky\u001b[1;34m(A, out, jitter, max_tries)\u001b[0m\n\u001b[0;32m     18\u001b[0m     out \u001b[38;5;241m=\u001b[39m (out, torch\u001b[38;5;241m.\u001b[39mempty(A\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mint32, device\u001b[38;5;241m=\u001b[39mout\u001b[38;5;241m.\u001b[39mdevice))\n\u001b[0;32m     20\u001b[0m L, info \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mcholesky_ex(A, out\u001b[38;5;241m=\u001b[39mout)\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m settings\u001b[38;5;241m.\u001b[39mtrace_mode\u001b[38;5;241m.\u001b[39mon() \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39many(info):\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m L\n\u001b[0;32m     24\u001b[0m isnan \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39misnan(A)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import gpytorch\n",
    "import tqdm\n",
    "import gc\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "class GPRegressionModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super().__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        base_covar = gpytorch.kernels.ScaleKernel(\n",
    "            gpytorch.kernels.MaternKernel(nu=1.5)\n",
    "        )\n",
    "        self.covar_module = gpytorch.kernels.InducingPointKernel(\n",
    "            base_covar,\n",
    "            #inducing_points=train_x[::15000].clone(),\n",
    "            inducing_points=train_x[torch.randperm(train_x.shape[0])[:100]].clone(),\n",
    "            likelihood=likelihood\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "    \n",
    "\n",
    "\n",
    "class GPRegressionModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(GPRegressionModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = ConstantMean()\n",
    "        self.base_covar_module = ScaleKernel(gpytorch.kernels.MaternKernel(nu=1.5, ard_num_dims=2))\n",
    "        self.covar_module = InducingPointKernel(self.base_covar_module, inducing_points=torch.linspace(train_x.min(), train_x.max(), steps=40).unsqueeze(-1), likelihood=likelihood)\n",
    "        #print(\"VRAM Usage:\", torch.cuda.memory_allocated()/(1024**2) , \"MB\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        #print(\"VRAM Usage:\", torch.cuda.memory_allocated()/(1024**2) , \"MB\")\n",
    "        return MultivariateNormal(mean_x, covar_x)\n",
    "    \n",
    "\n",
    "# Experiment Parameters\n",
    "# -----------------------------\n",
    "n_replicates = 11\n",
    "training_iterations = 125\n",
    "n_train, n_test = 400000, 20000\n",
    "random_state = 422\n",
    "gpu = torch.cuda.is_available()\n",
    "gpu = True\n",
    "\n",
    "mse_l_sgpr = []\n",
    "time_l_sgpr = []\n",
    "vram_l_sgpr = []\n",
    "\n",
    "# -----------------------------\n",
    "# Replicates Loop\n",
    "# -----------------------------\n",
    "for rep in range(n_replicates):\n",
    "    print(f\"\\n=== Replicate {rep + 1}/{n_replicates} ===\")\n",
    "\n",
    "    # ---- Split Data ----\n",
    "    train_x, train_y, test_x, test_y = splitter(\n",
    "        all_x, all_y,\n",
    "        n_train=n_train, n_test=n_test,\n",
    "        random_state=random_state + rep,\n",
    "        move_to_gpu=gpu\n",
    "    )\n",
    "    ram_init = get_mem()\n",
    "    # ---- Initialize ----\n",
    "    likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "    model = GPRegressionModel(train_x, train_y, likelihood)\n",
    "    if gpu:\n",
    "        model = model.cuda()\n",
    "        likelihood = likelihood.cuda()\n",
    "    \n",
    "    model.train()\n",
    "    likelihood.train()\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.02)\n",
    "    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "    model = model.double()\n",
    "    likelihood = likelihood.double()\n",
    "\n",
    "    # ---- Train ----\n",
    "    start = time.time()\n",
    "    iterator = tqdm.tqdm(range(training_iterations), desc=f\"Train {rep + 1}\")\n",
    "\n",
    "    for it in iterator:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(train_x)\n",
    "        loss = -mll(output, train_y)\n",
    "        loss.backward()\n",
    "        iterator.set_postfix(loss=loss.item())  # <-- Add this line\n",
    "        optimizer.step()\n",
    "        torch.cuda.empty_cache()\n",
    "    elapsed = time.time() - start\n",
    "\n",
    "    ram_diff = get_mem() - ram_init\n",
    "    model.eval()\n",
    "    likelihood.eval()\n",
    "    with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "        pred = likelihood(model(test_x)).mean.cpu()\n",
    "    mse = torch.mean((pred - test_y.cpu()) ** 2).item()\n",
    "    peak_alloc, peak_reserved, gpu_used, sys_used = log_memory()\n",
    "    mse_l_sgpr.append(mse)\n",
    "    time_l_sgpr.append(elapsed)\n",
    "    vram_l_sgpr.append(peak_alloc)\n",
    "    print(f\"Rep {rep + 1}: MSE={mse:.4f}, Time={elapsed:.2f}s, VRAM={peak_alloc:.2f}MB, RAM diff={ram_diff:.2f}MB\")\n",
    "    del model, likelihood\n",
    "    gc.collect()\n",
    "    if gpu:\n",
    "        torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097d17fa-8cbd-4bc5-92cd-a6e51066d107",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(statistics.mean(mse_l_sgpr[1:]))\n",
    "print(statistics.stdev(mse_l_sgpr[1:]))\n",
    "\n",
    "print(statistics.mean(time_l_sgpr[1:]))\n",
    "print(statistics.stdev(time_l_sgpr[1:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b424e738-8f9e-4027-b302-a7a6eb2a4784",
   "metadata": {},
   "source": [
    "# LOVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520eddc5-3859-4dd7-b92d-67304487353a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lanczos Variance Estimates (LOVE)\n",
    "max_vram = 0\n",
    "gc.collect()\n",
    "if gpu:\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ed2886-f6e2-42b7-b5c8-72a61f4bc513",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gpytorch\n",
    "import tqdm\n",
    "import time\n",
    "import gc\n",
    "import numpy as np\n",
    "import psutil\n",
    "\n",
    "# -----------------------------\n",
    "# Feature Extractor\n",
    "# -----------------------------\n",
    "class LargeFeatureExtractor(torch.nn.Sequential):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.add_module('linear1', torch.nn.Linear(input_dim, 1000))\n",
    "        self.add_module('relu1', torch.nn.ReLU())\n",
    "        self.add_module('linear2', torch.nn.Linear(1000, 500))\n",
    "        self.add_module('relu2', torch.nn.ReLU())\n",
    "        self.add_module('linear3', torch.nn.Linear(500, 50))\n",
    "        self.add_module('relu3', torch.nn.ReLU())\n",
    "        self.add_module('linear4', torch.nn.Linear(50, 1))\n",
    "\n",
    "# -----------------------------\n",
    "# GPRegressionModel\n",
    "# -----------------------------\n",
    "class GPRegressionModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super().__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.GridInterpolationKernel(\n",
    "            gpytorch.kernels.ScaleKernel(\n",
    "                gpytorch.kernels.MaternKernel(nu=1.5, ard_num_dims=1)\n",
    "            ),\n",
    "            grid_size=100, num_dims=1\n",
    "        )\n",
    "        self.feature_extractor = LargeFeatureExtractor(input_dim=train_x.size(-1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        projected_x = self.feature_extractor(x)\n",
    "        projected_x = projected_x - projected_x.min(0)[0]\n",
    "        projected_x = 2 * (projected_x / projected_x.max(0)[0]) - 1\n",
    "        mean_x = self.mean_module(projected_x)\n",
    "        covar_x = self.covar_module(projected_x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "# -----------------------------\n",
    "# Experiment Parameters\n",
    "# -----------------------------\n",
    "n_replicates = 11\n",
    "training_iterations = 100\n",
    "n_train, n_test = 80000, 20000\n",
    "training_iterations = 25\n",
    "n_train, n_test = 400000, 100000\n",
    "random_state = 42\n",
    "gpu = torch.cuda.is_available()\n",
    "\n",
    "mse_l_love = []\n",
    "time_l_love = []\n",
    "vram_l_love = []\n",
    "ram_l_love = []\n",
    "\n",
    "# -----------------------------\n",
    "# Replicates Loop\n",
    "# -----------------------------\n",
    "for rep in range(n_replicates):\n",
    "    print(f\"\\n=== Replicate {rep + 1}/{n_replicates} ===\")\n",
    "\n",
    "    # ---- Split Data ----\n",
    "    train_x, train_y, test_x, test_y = splitter(\n",
    "        all_x, all_y,\n",
    "        n_train=n_train, n_test=n_test,\n",
    "        random_state=random_state + rep,\n",
    "        move_to_gpu=gpu\n",
    "    )\n",
    "\n",
    "    # ---- RAM before model ----\n",
    "    mem_begin = psutil.virtual_memory().used / (1024 ** 2)  # in MB\n",
    "\n",
    "    # ---- Initialize ----\n",
    "    likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "    model = GPRegressionModel(train_x, train_y, likelihood)\n",
    "    if gpu:\n",
    "        model = model.cuda()\n",
    "        likelihood = likelihood.cuda()\n",
    "\n",
    "    model.train()\n",
    "    likelihood.train()\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "    if gpu:\n",
    "        mll = mll.cuda()\n",
    "\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "    # ---- Train ----\n",
    "    start = time.time()\n",
    "    iterator = tqdm.tqdm(range(training_iterations), desc=f\"Train {rep + 1}\")\n",
    "    for it in iterator:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(train_x)\n",
    "        loss = -mll(output, train_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        iterator.set_postfix(loss=loss.item())\n",
    "    elapsed = time.time() - start\n",
    "\n",
    "    # ---- RAM after ----\n",
    "    mem_end = psutil.virtual_memory().used / (1024 ** 2)  # in MB\n",
    "    delta_ram = mem_end - mem_begin\n",
    "\n",
    "    # ---- Evaluate ----\n",
    "    model.eval()\n",
    "    likelihood.eval()\n",
    "    with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "        observed_pred = likelihood(model(test_x))\n",
    "    means = observed_pred.mean.cpu()\n",
    "    mse = torch.mean((means - test_y.cpu()) ** 2).item()\n",
    "\n",
    "    # ---- Log Resources ----\n",
    "    peak_alloc, peak_reserved, gpu_used, sys_used = log_memory()\n",
    "\n",
    "    mse_l_love.append(mse)\n",
    "    time_l_love.append(elapsed)\n",
    "    vram_l_love.append(peak_alloc)\n",
    "    ram_l_love.append(delta_ram)\n",
    "\n",
    "    print(f\"LoVE Rep {rep + 1}: MSE={mse:.4f}, Time={elapsed:.2f}s, RAM Î”={delta_ram:.2f}MB, VRAM={peak_alloc:.2f}MB\")\n",
    "\n",
    "    # ---- Cleanup ----\n",
    "    del model, likelihood\n",
    "    gc.collect()\n",
    "    if gpu:\n",
    "        torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e43d83-1b30-4d8b-8058-cf4c8d840b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(statistics.mean(mse_l_love[1:]))\n",
    "print(statistics.stdev(mse_l_love[1:]))\n",
    "\n",
    "print(statistics.mean(time_l_love[1:]))\n",
    "print(statistics.stdev(time_l_love[1:]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d90f64c-2426-45ef-be6f-94cd98b9f010",
   "metadata": {},
   "source": [
    "# DKL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae0c28c-fdeb-42ac-9255-752e4c809f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep Kernel Learning\n",
    "max_vram = 0\n",
    "gc.collect()\n",
    "if gpu:\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7cc8db-cfc4-4ef2-8e2f-fb03fabf92bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gpytorch\n",
    "import tqdm\n",
    "import time\n",
    "import gc\n",
    "import numpy as np\n",
    "import psutil\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# DKL Feature Extractor\n",
    "# -----------------------------\n",
    "class LargeFeatureExtractor(torch.nn.Sequential):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.add_module('linear1', torch.nn.Linear(input_dim, 1000))\n",
    "        self.add_module('relu1', torch.nn.ReLU())\n",
    "        self.add_module('linear2', torch.nn.Linear(1000, 500))\n",
    "        self.add_module('relu2', torch.nn.ReLU())\n",
    "        self.add_module('linear3', torch.nn.Linear(500, 50))\n",
    "        self.add_module('relu3', torch.nn.ReLU())\n",
    "        self.add_module('linear4', torch.nn.Linear(50, 1))\n",
    "\n",
    "# -----------------------------\n",
    "# GPRegressionModel\n",
    "# -----------------------------\n",
    "class GPRegressionModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood, input_dim):\n",
    "        super().__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.GridInterpolationKernel(\n",
    "            gpytorch.kernels.ScaleKernel(\n",
    "                gpytorch.kernels.MaternKernel(nu=1.5, ard_num_dims=1)\n",
    "            ),\n",
    "            num_dims=1, grid_size=100\n",
    "        )\n",
    "        self.feature_extractor = LargeFeatureExtractor(input_dim=input_dim)\n",
    "        self.scale_to_bounds = gpytorch.utils.grid.ScaleToBounds(-1., 1.)\n",
    "\n",
    "    def forward(self, x):\n",
    "        projected_x = self.feature_extractor(x)\n",
    "        projected_x = self.scale_to_bounds(projected_x)\n",
    "        mean_x = self.mean_module(projected_x)\n",
    "        covar_x = self.covar_module(projected_x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "# -----------------------------\n",
    "# Experiment Parameters\n",
    "# -----------------------------\n",
    "n_replicates = 11\n",
    "training_iterations = 80\n",
    "n_train, n_test = 400000, 20000\n",
    "random_state = 42\n",
    "gpu = torch.cuda.is_available()\n",
    "\n",
    "mse_l_dkl = []\n",
    "time_l_dkl = []\n",
    "vram_l_dkl = []\n",
    "ram_l_dkl = []\n",
    "\n",
    "# -----------------------------\n",
    "# Replicates Loop\n",
    "# -----------------------------\n",
    "for rep in range(n_replicates):\n",
    "    print(f\"\\n=== Replicate {rep + 1}/{n_replicates} ===\")\n",
    "\n",
    "    # ---- Split Data ----\n",
    "    train_x, train_y, test_x, test_y = splitter(\n",
    "        all_x, all_y,\n",
    "        n_train=n_train, n_test=n_test,\n",
    "        random_state=random_state + rep,\n",
    "        move_to_gpu=gpu\n",
    "    )\n",
    "\n",
    "    # ---- RAM before model ----\n",
    "    mem_begin = psutil.virtual_memory().used / (1024 ** 2)  # in MB\n",
    "\n",
    "    # ---- Initialize ----\n",
    "    likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "    model = GPRegressionModel(train_x, train_y, likelihood, input_dim=train_x.size(-1))\n",
    "    if gpu:\n",
    "        model = model.cuda()\n",
    "        likelihood = likelihood.cuda()\n",
    "\n",
    "    model.train()\n",
    "    likelihood.train()\n",
    "\n",
    "    optimizer = torch.optim.Adam([\n",
    "        {'params': model.feature_extractor.parameters()},\n",
    "        {'params': model.covar_module.parameters()},\n",
    "        {'params': model.mean_module.parameters()},\n",
    "        {'params': model.likelihood.parameters()},\n",
    "    ], lr=0.01)\n",
    "\n",
    "    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "    if gpu:\n",
    "        mll = mll.cuda()\n",
    "\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "    # ---- Train ----\n",
    "    start = time.time()\n",
    "    iterator = tqdm.tqdm(range(training_iterations), desc=f\"Train {rep + 1}\")\n",
    "    for it in iterator:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(train_x)\n",
    "        loss = -mll(output, train_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        iterator.set_postfix(loss=loss.item())\n",
    "    elapsed = time.time() - start\n",
    "\n",
    "    # ---- RAM after ----\n",
    "    mem_end = psutil.virtual_memory().used / (1024 ** 2)\n",
    "    delta_ram = mem_end - mem_begin\n",
    "\n",
    "    # ---- Evaluate ----\n",
    "    model.eval()\n",
    "    likelihood.eval()\n",
    "    with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "        observed_pred = likelihood(model(test_x))\n",
    "    means = observed_pred.mean.cpu()\n",
    "    mse = torch.mean((means - test_y.cpu()) ** 2).item()\n",
    "\n",
    "    # ---- Log Resources ----\n",
    "    peak_alloc, peak_reserved, gpu_used, sys_used = log_memory()\n",
    "\n",
    "    mse_l_dkl.append(mse)\n",
    "    time_l_dkl.append(elapsed)\n",
    "    vram_l_dkl.append(peak_alloc)\n",
    "    ram_l_dkl.append(delta_ram)\n",
    "\n",
    "    print(f\"DKL Rep {rep + 1}: MSE={mse:.4f}, Time={elapsed:.2f}s, RAM Î”={delta_ram:.2f}MB, VRAM={peak_alloc:.2f}MB\")\n",
    "\n",
    "    # ---- Cleanup ----\n",
    "    del model, likelihood\n",
    "    gc.collect()\n",
    "    if gpu:\n",
    "        torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac51aa14-6510-4d76-9fcd-4a025320087f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(statistics.mean(mse_l_dkl[1:]))\n",
    "print(statistics.stdev(mse_l_dkl[1:]))\n",
    "\n",
    "print(statistics.mean(time_l_dkl[1:]))\n",
    "print(statistics.stdev(time_l_dkl[1:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9eab984-9b64-4e7f-9532-039bbb00be33",
   "metadata": {},
   "source": [
    "# SVGP CI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b464d4-2ff1-4d2f-a573-ae6822d71849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVGP_CI\n",
    "max_vram = 0\n",
    "gc.collect()\n",
    "if gpu:\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0611cb-3119-4842-a668-3c2acd3fcf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gpytorch\n",
    "import tqdm\n",
    "import time\n",
    "import gc\n",
    "import numpy as np\n",
    "import psutil\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "\n",
    "class GPModel(gpytorch.models.ApproximateGP):\n",
    "    def __init__(self, inducing_points):\n",
    "        variational_distribution = gpytorch.variational.NaturalVariationalDistribution(inducing_points.size(0))\n",
    "        variational_strategy = gpytorch.variational.CiqVariationalStrategy(\n",
    "            self, inducing_points, variational_distribution, learn_inducing_locations=True\n",
    "        )\n",
    "        super().__init__(variational_strategy)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(\n",
    "            gpytorch.kernels.MaternKernel(nu=1.5, ard_num_dims=2)\n",
    "        )\n",
    "        self.covar_module.base_kernel.initialize(lengthscale=0.01)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "\n",
    "n_replicates = 11\n",
    "num_epochs = 5\n",
    "batch_size = 3200\n",
    "random_state = 42\n",
    "gpu = torch.cuda.is_available()\n",
    "\n",
    "mse_l_svgpci = []\n",
    "time_l_svgpci = []\n",
    "vram_l_svgpci = []\n",
    "ram_l_svgpci = []\n",
    "\n",
    "\n",
    "for rep in range(n_replicates):\n",
    "    print(f\"\\n=== Replicate {rep + 1}/{n_replicates} ===\")\n",
    "    train_x, train_y, test_x, test_y = splitter(\n",
    "        all_x, all_y,\n",
    "        n_train=400000, n_test=20000,\n",
    "        random_state=random_state + rep,\n",
    "        move_to_gpu=gpu\n",
    "    )\n",
    "\n",
    "    mem_begin = psutil.virtual_memory().used / (1024 ** 2)\n",
    "    torch.linspace(train_x.min(), train_x.max(), steps=80).unsqueeze(-1)\n",
    "    train_dataset = TensorDataset(train_x, train_y)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_dataset = TensorDataset(test_x, test_y)\n",
    "    inducing_points = torch.linspace(0.2, 0.8, 100).unsqueeze(-1)\n",
    "    model = GPModel(inducing_points=inducing_points)\n",
    "    likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "\n",
    "    if gpu:\n",
    "        model = model.cuda()\n",
    "        likelihood = likelihood.cuda()\n",
    "\n",
    "    variational_ngd_optimizer = gpytorch.optim.NGD(\n",
    "        model.variational_parameters(), num_data=train_y.size(0), lr=0.1\n",
    "    )\n",
    "    hyperparameter_optimizer = torch.optim.Adam([\n",
    "        {'params': model.hyperparameters()},\n",
    "        {'params': likelihood.parameters()},\n",
    "    ], lr=0.002)\n",
    "\n",
    "    model.train()\n",
    "    likelihood.train()\n",
    "    mll = gpytorch.mlls.VariationalELBO(likelihood, model, num_data=train_y.size(0))\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "    start = time.time()\n",
    "    epochs_iter = tqdm.tqdm(range(num_epochs), desc=f\"Epoch {rep + 1}\")\n",
    "    for epoch in epochs_iter:\n",
    "        minibatch_iter = tqdm.tqdm(train_loader, desc=\"Minibatch\", leave=False, position=0)\n",
    "        for x_batch, y_batch in minibatch_iter:\n",
    "            variational_ngd_optimizer.zero_grad()\n",
    "            hyperparameter_optimizer.zero_grad()\n",
    "            output = model(x_batch)\n",
    "            loss = -mll(output, y_batch)\n",
    "            loss.backward()\n",
    "            variational_ngd_optimizer.step()\n",
    "            hyperparameter_optimizer.step()\n",
    "            minibatch_iter.set_postfix(loss=loss.item())\n",
    "    elapsed = time.time() - start\n",
    "    mem_end = psutil.virtual_memory().used / (1024 ** 2)\n",
    "    delta_ram = mem_end - mem_begin\n",
    "    model.eval()\n",
    "    likelihood.eval()\n",
    "    with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "        observed_pred = likelihood(model(test_x))\n",
    "    means = observed_pred.mean.cpu()\n",
    "    mse = torch.mean((means - test_y.cpu()) ** 2).item()\n",
    "    peak_alloc, peak_reserved, gpu_used, sys_used = log_memory()\n",
    "    mse_l_svgpci.append(mse)\n",
    "    time_l_svgpci.append(elapsed)\n",
    "    vram_l_svgpci.append(peak_alloc)\n",
    "    ram_l_svgpci.append(delta_ram)\n",
    "    print(f\"SVGP-CIQ Rep {rep + 1}: MSE={mse:.4f}, Time={elapsed:.2f}s, RAM Î”={delta_ram:.2f}MB, VRAM={peak_alloc:.2f}MB\")\n",
    "    del model, likelihood\n",
    "    gc.collect()\n",
    "    if gpu:\n",
    "        torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f1f02c-431f-48d7-9da1-7d52ff797bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(statistics.mean(mse_l_svgpci[1:]))\n",
    "print(statistics.stdev(mse_l_svgpci[1:]))\n",
    "\n",
    "print(statistics.mean(time_l_svgpci[1:]))\n",
    "print(statistics.stdev(time_l_svgpci[1:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28302cc4-1b8d-4544-a4a6-8146d8d0dba6",
   "metadata": {},
   "source": [
    "# SVGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652e35f6-e4f9-4e8b-bb46-5cd07f7f9417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVGP\n",
    "max_vram = 0\n",
    "gc.collect()\n",
    "if gpu:\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8834b3b8-9790-4eb1-851e-f0ff48390b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Replicate 1/11 ===\n",
      "21682.4375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 0/2 [00:09<?, ?it/s]                             \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 75\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x_batch, y_batch \u001b[38;5;129;01min\u001b[39;00m minibatch_iter:\n\u001b[0;32m     74\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 75\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     76\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mmll(output, y_batch)\n\u001b[0;32m     77\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\scaleGP\\lib\\site-packages\\gpytorch\\models\\approximate_gp.py:114\u001b[0m, in \u001b[0;36mApproximateGP.__call__\u001b[1;34m(self, inputs, prior, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    113\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvariational_strategy(inputs, prior\u001b[38;5;241m=\u001b[39mprior, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\scaleGP\\lib\\site-packages\\gpytorch\\variational\\variational_strategy.py:272\u001b[0m, in \u001b[0;36mVariationalStrategy.__call__\u001b[1;34m(self, x, prior, **kwargs)\u001b[0m\n\u001b[0;32m    269\u001b[0m         \u001b[38;5;66;03m# Mark that we have updated the variational strategy\u001b[39;00m\n\u001b[0;32m    270\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdated_strategy\u001b[38;5;241m.\u001b[39mfill_(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 272\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(x, prior\u001b[38;5;241m=\u001b[39mprior, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\scaleGP\\lib\\site-packages\\gpytorch\\variational\\_variational_strategy.py:347\u001b[0m, in \u001b[0;36m_VariationalStrategy.__call__\u001b[1;34m(self, x, prior, **kwargs)\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# Get q(f)\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(variational_dist_u, MultivariateNormal):\n\u001b[1;32m--> 347\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\n\u001b[0;32m    348\u001b[0m         x,\n\u001b[0;32m    349\u001b[0m         inducing_points,\n\u001b[0;32m    350\u001b[0m         inducing_values\u001b[38;5;241m=\u001b[39mvariational_dist_u\u001b[38;5;241m.\u001b[39mmean,\n\u001b[0;32m    351\u001b[0m         variational_inducing_covar\u001b[38;5;241m=\u001b[39mvariational_dist_u\u001b[38;5;241m.\u001b[39mlazy_covariance_matrix,\n\u001b[0;32m    352\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    353\u001b[0m     )\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(variational_dist_u, Delta):\n\u001b[0;32m    355\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\n\u001b[0;32m    356\u001b[0m         x, inducing_points, inducing_values\u001b[38;5;241m=\u001b[39mvariational_dist_u\u001b[38;5;241m.\u001b[39mmean, variational_inducing_covar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    357\u001b[0m     )\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\scaleGP\\lib\\site-packages\\gpytorch\\module.py:31\u001b[0m, in \u001b[0;36mModule.__call__\u001b[1;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Tensor, Distribution, LinearOperator]:\n\u001b[1;32m---> 31\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(\u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m     33\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [_validate_module_outputs(output) \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m outputs]\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\scaleGP\\lib\\site-packages\\gpytorch\\variational\\variational_strategy.py:203\u001b[0m, in \u001b[0;36mVariationalStrategy.forward\u001b[1;34m(self, x, inducing_points, inducing_values, variational_inducing_covar, **kwargs)\u001b[0m\n\u001b[0;32m    198\u001b[0m data_data_covar \u001b[38;5;241m=\u001b[39m full_covar[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, num_induc:, num_induc:]\n\u001b[0;32m    200\u001b[0m \u001b[38;5;66;03m# Compute interpolation terms\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;66;03m# K_ZZ^{-1/2} K_ZX\u001b[39;00m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;66;03m# K_ZZ^{-1/2} \\mu_Z\u001b[39;00m\n\u001b[1;32m--> 203\u001b[0m L \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cholesky_factor\u001b[49m\u001b[43m(\u001b[49m\u001b[43minduc_induc_covar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m L\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m induc_induc_covar\u001b[38;5;241m.\u001b[39mshape:\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;66;03m# Aggressive caching can cause nasty shape incompatibilies when evaluating with different batch shapes\u001b[39;00m\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;66;03m# TODO: Use a hook fo this\u001b[39;00m\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\scaleGP\\lib\\site-packages\\gpytorch\\utils\\memoize.py:76\u001b[0m, in \u001b[0;36m_cached_ignore_args.<locals>.g\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m cache_name \u001b[38;5;241m=\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m method\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_in_cache_ignore_args(\u001b[38;5;28mself\u001b[39m, cache_name):\n\u001b[1;32m---> 76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _add_to_cache_ignore_args(\u001b[38;5;28mself\u001b[39m, cache_name, method(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _get_from_cache_ignore_args(\u001b[38;5;28mself\u001b[39m, cache_name)\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\scaleGP\\lib\\site-packages\\gpytorch\\variational\\variational_strategy.py:104\u001b[0m, in \u001b[0;36mVariationalStrategy._cholesky_factor\u001b[1;34m(self, induc_induc_covar)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;129m@cached\u001b[39m(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcholesky_factor\u001b[39m\u001b[38;5;124m\"\u001b[39m, ignore_args\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_cholesky_factor\u001b[39m(\u001b[38;5;28mself\u001b[39m, induc_induc_covar: LinearOperator) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m TriangularLinearOperator:\n\u001b[1;32m--> 104\u001b[0m     L \u001b[38;5;241m=\u001b[39m psd_safe_cholesky(\u001b[43mto_dense\u001b[49m\u001b[43m(\u001b[49m\u001b[43minduc_induc_covar\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtype(_linalg_dtype_cholesky\u001b[38;5;241m.\u001b[39mvalue()))\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m TriangularLinearOperator(L)\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\scaleGP\\lib\\site-packages\\linear_operator\\operators\\_linear_operator.py:2993\u001b[0m, in \u001b[0;36mto_dense\u001b[1;34m(obj)\u001b[0m\n\u001b[0;32m   2991\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[0;32m   2992\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, LinearOperator):\n\u001b[1;32m-> 2993\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dense\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2994\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2995\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject of class \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m cannot be made into a Tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m))\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\scaleGP\\lib\\site-packages\\linear_operator\\utils\\memoize.py:59\u001b[0m, in \u001b[0;36m_cached.<locals>.g\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     57\u001b[0m kwargs_pkl \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mdumps(kwargs)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_in_cache(\u001b[38;5;28mself\u001b[39m, cache_name, \u001b[38;5;241m*\u001b[39margs, kwargs_pkl\u001b[38;5;241m=\u001b[39mkwargs_pkl):\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _add_to_cache(\u001b[38;5;28mself\u001b[39m, cache_name, method(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs), \u001b[38;5;241m*\u001b[39margs, kwargs_pkl\u001b[38;5;241m=\u001b[39mkwargs_pkl)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _get_from_cache(\u001b[38;5;28mself\u001b[39m, cache_name, \u001b[38;5;241m*\u001b[39margs, kwargs_pkl\u001b[38;5;241m=\u001b[39mkwargs_pkl)\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\scaleGP\\lib\\site-packages\\linear_operator\\operators\\sum_linear_operator.py:81\u001b[0m, in \u001b[0;36mSumLinearOperator.to_dense\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;129m@cached\u001b[39m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_dense\u001b[39m(\u001b[38;5;28mself\u001b[39m: Float[LinearOperator, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*batch M N\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Float[Tensor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*batch M N\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m---> 81\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlinear_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dense\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlinear_op\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear_ops\u001b[49m\u001b[43m)\u001b[49m)\u001b[38;5;241m.\u001b[39mcontiguous()\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\scaleGP\\lib\\site-packages\\linear_operator\\operators\\sum_linear_operator.py:81\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;129m@cached\u001b[39m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_dense\u001b[39m(\u001b[38;5;28mself\u001b[39m: Float[LinearOperator, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*batch M N\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Float[Tensor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*batch M N\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m---> 81\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28msum\u001b[39m(\u001b[43mlinear_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dense\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m linear_op \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear_ops))\u001b[38;5;241m.\u001b[39mcontiguous()\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\scaleGP\\lib\\site-packages\\gpytorch\\utils\\memoize.py:59\u001b[0m, in \u001b[0;36m_cached.<locals>.g\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     57\u001b[0m kwargs_pkl \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mdumps(kwargs)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_in_cache(\u001b[38;5;28mself\u001b[39m, cache_name, \u001b[38;5;241m*\u001b[39margs, kwargs_pkl\u001b[38;5;241m=\u001b[39mkwargs_pkl):\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _add_to_cache(\u001b[38;5;28mself\u001b[39m, cache_name, method(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs), \u001b[38;5;241m*\u001b[39margs, kwargs_pkl\u001b[38;5;241m=\u001b[39mkwargs_pkl)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _get_from_cache(\u001b[38;5;28mself\u001b[39m, cache_name, \u001b[38;5;241m*\u001b[39margs, kwargs_pkl\u001b[38;5;241m=\u001b[39mkwargs_pkl)\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\scaleGP\\lib\\site-packages\\gpytorch\\lazy\\lazy_evaluated_kernel_tensor.py:410\u001b[0m, in \u001b[0;36mLazyEvaluatedKernelTensor.to_dense\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    408\u001b[0m \u001b[38;5;129m@cached\u001b[39m\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_dense\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 410\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_kernel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto_dense()\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\scaleGP\\lib\\site-packages\\gpytorch\\utils\\memoize.py:59\u001b[0m, in \u001b[0;36m_cached.<locals>.g\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     57\u001b[0m kwargs_pkl \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mdumps(kwargs)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_in_cache(\u001b[38;5;28mself\u001b[39m, cache_name, \u001b[38;5;241m*\u001b[39margs, kwargs_pkl\u001b[38;5;241m=\u001b[39mkwargs_pkl):\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _add_to_cache(\u001b[38;5;28mself\u001b[39m, cache_name, method(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs), \u001b[38;5;241m*\u001b[39margs, kwargs_pkl\u001b[38;5;241m=\u001b[39mkwargs_pkl)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _get_from_cache(\u001b[38;5;28mself\u001b[39m, cache_name, \u001b[38;5;241m*\u001b[39margs, kwargs_pkl\u001b[38;5;241m=\u001b[39mkwargs_pkl)\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\scaleGP\\lib\\site-packages\\gpytorch\\lazy\\lazy_evaluated_kernel_tensor.py:25\u001b[0m, in \u001b[0;36mrecall_grad_state.<locals>.wrapped\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(method)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_grad_enabled):\n\u001b[1;32m---> 25\u001b[0m         output \u001b[38;5;241m=\u001b[39m method(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\scaleGP\\lib\\site-packages\\gpytorch\\lazy\\lazy_evaluated_kernel_tensor.py:355\u001b[0m, in \u001b[0;36mLazyEvaluatedKernelTensor.evaluate_kernel\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    353\u001b[0m     temp_active_dims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel\u001b[38;5;241m.\u001b[39mactive_dims\n\u001b[0;32m    354\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel\u001b[38;5;241m.\u001b[39mactive_dims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 355\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel(\n\u001b[0;32m    356\u001b[0m         x1,\n\u001b[0;32m    357\u001b[0m         x2,\n\u001b[0;32m    358\u001b[0m         diag\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    359\u001b[0m         last_dim_is_batch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_dim_is_batch,\n\u001b[0;32m    360\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams,\n\u001b[0;32m    361\u001b[0m     )\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel\u001b[38;5;241m.\u001b[39mactive_dims \u001b[38;5;241m=\u001b[39m temp_active_dims\n\u001b[0;32m    364\u001b[0m \u001b[38;5;66;03m# Check the size of the output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\scaleGP\\lib\\site-packages\\gpytorch\\kernels\\kernel.py:539\u001b[0m, in \u001b[0;36mKernel.__call__\u001b[1;34m(self, x1, x2, diag, last_dim_is_batch, **params)\u001b[0m\n\u001b[0;32m    536\u001b[0m     res \u001b[38;5;241m=\u001b[39m LazyEvaluatedKernelTensor(x1_, x2_, kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, last_dim_is_batch\u001b[38;5;241m=\u001b[39mlast_dim_is_batch, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    538\u001b[0m     res \u001b[38;5;241m=\u001b[39m to_linear_operator(\n\u001b[1;32m--> 539\u001b[0m         \u001b[38;5;28msuper\u001b[39m(Kernel, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(x1_, x2_, last_dim_is_batch\u001b[38;5;241m=\u001b[39mlast_dim_is_batch, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m    540\u001b[0m     )\n\u001b[0;32m    541\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\scaleGP\\lib\\site-packages\\gpytorch\\module.py:31\u001b[0m, in \u001b[0;36mModule.__call__\u001b[1;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Tensor, Distribution, LinearOperator]:\n\u001b[1;32m---> 31\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(\u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m     33\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [_validate_module_outputs(output) \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m outputs]\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\scaleGP\\lib\\site-packages\\gpytorch\\kernels\\scale_kernel.py:109\u001b[0m, in \u001b[0;36mScaleKernel.forward\u001b[1;34m(self, x1, x2, last_dim_is_batch, diag, **params)\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x1, x2, last_dim_is_batch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, diag\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams):\n\u001b[1;32m--> 109\u001b[0m     orig_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_kernel\u001b[38;5;241m.\u001b[39mforward(x1, x2, diag\u001b[38;5;241m=\u001b[39mdiag, last_dim_is_batch\u001b[38;5;241m=\u001b[39mlast_dim_is_batch, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m    110\u001b[0m     outputscales \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutputscale\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m last_dim_is_batch:\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\scaleGP\\lib\\site-packages\\gpytorch\\kernels\\matern_kernel.py:109\u001b[0m, in \u001b[0;36mMaternKernel.forward\u001b[1;34m(self, x1, x2, diag, **params)\u001b[0m\n\u001b[0;32m    107\u001b[0m         constant_component \u001b[38;5;241m=\u001b[39m (math\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;241m5\u001b[39m) \u001b[38;5;241m*\u001b[39m distance)\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;241m5.0\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m3.0\u001b[39m \u001b[38;5;241m*\u001b[39m distance\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m constant_component \u001b[38;5;241m*\u001b[39m exp_component\n\u001b[1;32m--> 109\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mMaternCovariance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlengthscale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx2\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcovar_dist\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\scaleGP\\lib\\site-packages\\torch\\autograd\\function.py:575\u001b[0m, in \u001b[0;36mFunction.apply\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[0;32m    573\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[0;32m    574\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[1;32m--> 575\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    579\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    580\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    581\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    582\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/main/notes/extending.func.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    583\u001b[0m     )\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\scaleGP\\lib\\site-packages\\gpytorch\\functions\\matern_covariance.py:19\u001b[0m, in \u001b[0;36mMaternCovariance.forward\u001b[1;34m(ctx, x1, x2, lengthscale, nu, dist_func)\u001b[0m\n\u001b[0;32m     17\u001b[0m x1_ \u001b[38;5;241m=\u001b[39m (x1 \u001b[38;5;241m-\u001b[39m mean)\u001b[38;5;241m.\u001b[39mdiv(lengthscale)\n\u001b[0;32m     18\u001b[0m x2_ \u001b[38;5;241m=\u001b[39m (x2 \u001b[38;5;241m-\u001b[39m mean)\u001b[38;5;241m.\u001b[39mdiv(lengthscale)\n\u001b[1;32m---> 19\u001b[0m scaled_unitless_dist \u001b[38;5;241m=\u001b[39m \u001b[43mdist_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx2_\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmul_(math\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m nu))\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nu \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0.5\u001b[39m:\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;66;03m# 1 kernel sized Tensor if no grad else 2\u001b[39;00m\n\u001b[0;32m     22\u001b[0m     scaled_unitless_dist_ \u001b[38;5;241m=\u001b[39m scaled_unitless_dist\u001b[38;5;241m.\u001b[39mclone() \u001b[38;5;28;01mif\u001b[39;00m needs_grad \u001b[38;5;28;01melse\u001b[39;00m scaled_unitless_dist\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\scaleGP\\lib\\site-packages\\gpytorch\\kernels\\matern_kernel.py:110\u001b[0m, in \u001b[0;36mMaternKernel.forward.<locals>.<lambda>\u001b[1;34m(x1, x2)\u001b[0m\n\u001b[0;32m    107\u001b[0m         constant_component \u001b[38;5;241m=\u001b[39m (math\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;241m5\u001b[39m) \u001b[38;5;241m*\u001b[39m distance)\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;241m5.0\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m3.0\u001b[39m \u001b[38;5;241m*\u001b[39m distance\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m constant_component \u001b[38;5;241m*\u001b[39m exp_component\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m MaternCovariance\u001b[38;5;241m.\u001b[39mapply(\n\u001b[1;32m--> 110\u001b[0m     x1, x2, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlengthscale, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnu, \u001b[38;5;28;01mlambda\u001b[39;00m x1, x2: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcovar_dist(x1, x2, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m    111\u001b[0m )\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\scaleGP\\lib\\site-packages\\gpytorch\\kernels\\kernel.py:345\u001b[0m, in \u001b[0;36mKernel.covar_dist\u001b[1;34m(self, x1, x2, diag, last_dim_is_batch, square_dist, **params)\u001b[0m\n\u001b[0;32m    342\u001b[0m     x1 \u001b[38;5;241m=\u001b[39m x1\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    343\u001b[0m     x2 \u001b[38;5;241m=\u001b[39m x2\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 345\u001b[0m x1_eq_x2 \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mequal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    346\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m diag:\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;66;03m# Special case the diagonal because we can return all zeros most of the time.\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import gpytorch\n",
    "import tqdm\n",
    "import time\n",
    "import gc\n",
    "import numpy as np\n",
    "import psutil\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from gpytorch.models import ApproximateGP\n",
    "from gpytorch.variational import VariationalStrategy, CholeskyVariationalDistribution\n",
    "\n",
    "\n",
    "\n",
    "class GPModel(ApproximateGP):\n",
    "    def __init__(self, inducing_points):\n",
    "        variational_distribution = CholeskyVariationalDistribution(inducing_points.size(0))\n",
    "        variational_strategy = VariationalStrategy(\n",
    "            self, inducing_points, variational_distribution, learn_inducing_locations=False\n",
    "        )\n",
    "        super().__init__(variational_strategy)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(\n",
    "            gpytorch.kernels.MaternKernel(nu=1.5)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "\n",
    "n_replicates = 11\n",
    "num_epochs = 2#6\n",
    "batch_size = 32\n",
    "random_state = 42\n",
    "gpu = torch.cuda.is_available()\n",
    "\n",
    "mse_l_svgp = []\n",
    "time_l_svgp = []\n",
    "vram_l_svgp = []\n",
    "ram_l_svgp = []\n",
    "\n",
    "\n",
    "for rep in range(n_replicates):\n",
    "    print(f\"\\n=== Replicate {rep + 1}/{n_replicates} ===\")\n",
    "    train_x, train_y, test_x, test_y = splitter(\n",
    "        all_x, all_y,\n",
    "        n_train=400000, n_test=20000,\n",
    "        random_state=random_state + rep,\n",
    "        move_to_gpu=gpu\n",
    "    )\n",
    "    inducing_points = torch.linspace(0.2, 0.8, 100).unsqueeze(-1)\n",
    "    train_dataset = TensorDataset(train_x, train_y)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_dataset = TensorDataset(test_x, test_y)\n",
    "    mem_begin = psutil.virtual_memory().used / (1024 ** 2)\n",
    "    print(mem_begin)\n",
    "    model = GPModel(inducing_points=inducing_points)\n",
    "    likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "    if gpu:\n",
    "        model = model.cuda()\n",
    "        likelihood = likelihood.cuda()\n",
    "    optimizer = torch.optim.Adam([\n",
    "        {'params': model.parameters()},\n",
    "        {'params': likelihood.parameters()},\n",
    "    ], lr=0.005)\n",
    "    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "    start = time.time()\n",
    "    epochs_iter = tqdm.tqdm(range(num_epochs), desc=f\"Epoch {rep + 1}\")\n",
    "    for epoch in epochs_iter:\n",
    "        minibatch_iter = tqdm.tqdm(train_loader, desc=\"Minibatch\", leave=False, position=0)\n",
    "        for x_batch, y_batch in minibatch_iter:\n",
    "            optimizer.zero_grad()\n",
    "            output = model(x_batch)\n",
    "            loss = -mll(output, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            minibatch_iter.set_postfix(loss=loss.item())\n",
    "    elapsed = time.time() - start\n",
    "    mem_end = psutil.virtual_memory().used / (1024 ** 2)\n",
    "    print(mem_end)\n",
    "    delta_ram = mem_end - mem_begin\n",
    "    model.eval()\n",
    "    likelihood.eval()\n",
    "    with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "        observed_pred = likelihood(model(test_x))\n",
    "    means = observed_pred.mean.cpu()\n",
    "    mse = torch.mean((means - test_y.cpu()) ** 2).item()\n",
    "    peak_alloc, peak_reserved, gpu_used, sys_used = log_memory()\n",
    "    mse_l_svgp.append(mse)\n",
    "    time_l_svgp.append(elapsed)\n",
    "    vram_l_svgp.append(peak_alloc)\n",
    "    ram_l_svgp.append(delta_ram)\n",
    "    print(f\"SVGP Rep {rep + 1}: MSE={mse:.4f}, Time={elapsed:.2f}s, RAM Î”={delta_ram:.2f}MB, VRAM={peak_alloc:.2f}MB\")\n",
    "    del model, likelihood\n",
    "    gc.collect()\n",
    "    if gpu:\n",
    "        torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57924823-1f7c-46cf-8e3f-73daf54ccc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(statistics.mean(mse_l_svgp[1:]))\n",
    "print(statistics.stdev(mse_l_svgp[1:]))\n",
    "\n",
    "print(statistics.mean(time_l_svgp[1:]))\n",
    "print(statistics.stdev(time_l_svgp[1:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174305f1-9eca-4bfb-8b45-55dcb521db47",
   "metadata": {},
   "source": [
    "# NGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ec3b4b-9332-4954-8e4e-6c688b0fcac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NGD\n",
    "max_vram = 0\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41490c0b-1b29-4b3f-882d-0835174f149e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gpytorch\n",
    "import tqdm\n",
    "import time\n",
    "import gc\n",
    "import numpy as np\n",
    "import psutil\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "\n",
    "\n",
    "class GPModel(gpytorch.models.ApproximateGP):\n",
    "    def __init__(self, inducing_points):\n",
    "        variational_distribution = gpytorch.variational.NaturalVariationalDistribution(inducing_points.size(0))\n",
    "        variational_strategy = gpytorch.variational.VariationalStrategy(\n",
    "            self, inducing_points, variational_distribution, learn_inducing_locations=False\n",
    "        )\n",
    "        super().__init__(variational_strategy)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.MaternKernel(nu=1.5))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "n_replicates = 11\n",
    "num_epochs = 20#60\n",
    "batch_size = 3200\n",
    "random_state = 42\n",
    "gpu = torch.cuda.is_available()\n",
    "\n",
    "mse_l_ngd = []\n",
    "time_l_ngd = []\n",
    "vram_l_ngd = []\n",
    "ram_l_ngd = []\n",
    "\n",
    "\n",
    "for rep in range(n_replicates):\n",
    "    print(f\"\\n=== Replicate {rep + 1}/{n_replicates} ===\")\n",
    "    train_x, train_y, test_x, test_y = splitter(\n",
    "        all_x, all_y,\n",
    "        n_train=400000, n_test=20000,\n",
    "        random_state=random_state + rep,\n",
    "        move_to_gpu=gpu\n",
    "    )\n",
    "    mem_begin = psutil.virtual_memory().used / (1024 ** 2)\n",
    "    inducing_points = torch.linspace(train_x.min(), train_x.max(), steps=50).unsqueeze(-1)\n",
    "    train_dataset = TensorDataset(train_x, train_y)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_dataset = TensorDataset(test_x, test_y)\n",
    "    model = GPModel(inducing_points=inducing_points)\n",
    "    likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "    if gpu:\n",
    "        model = model.cuda()\n",
    "        likelihood = likelihood.cuda()\n",
    "    variational_ngd_optimizer = gpytorch.optim.NGD(\n",
    "        model.variational_parameters(), num_data=train_y.size(0), lr=0.001\n",
    "    )\n",
    "    hyperparameter_optimizer = torch.optim.Adam([\n",
    "        {'params': model.hyperparameters()},\n",
    "        {'params': likelihood.parameters()},\n",
    "    ], lr=0.1)\n",
    "    model.train()\n",
    "    likelihood.train()\n",
    "    mll = gpytorch.mlls.VariationalELBO(likelihood, model, num_data=train_y.size(0))\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "    start = time.time()\n",
    "    epochs_iter = tqdm.tqdm(range(num_epochs), desc=f\"Epoch {rep + 1}\", leave=False, position=0)\n",
    "    for epoch in epochs_iter:\n",
    "        minibatch_iter = tqdm.tqdm(train_loader, desc=\"Minibatch\", leave=False, position=0)\n",
    "        for x_batch, y_batch in minibatch_iter:\n",
    "            variational_ngd_optimizer.zero_grad()\n",
    "            hyperparameter_optimizer.zero_grad()\n",
    "            output = model(x_batch)\n",
    "            loss = -mll(output, y_batch)\n",
    "            loss.backward()\n",
    "            variational_ngd_optimizer.step()\n",
    "            hyperparameter_optimizer.step()\n",
    "            minibatch_iter.set_postfix(loss=loss.item())\n",
    "    elapsed = time.time() - start\n",
    "\n",
    "    # ---- RAM after ----\n",
    "    mem_end = psutil.virtual_memory().used / (1024 ** 2)\n",
    "    delta_ram = mem_end - mem_begin\n",
    "\n",
    "    # ---- Evaluate ----\n",
    "    model.eval()\n",
    "    likelihood.eval()\n",
    "    with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "        observed_pred = likelihood(model(test_x))\n",
    "    means = observed_pred.mean.cpu()\n",
    "    mse = torch.mean((means - test_y.cpu()) ** 2).item()\n",
    "\n",
    "    # ---- Log Resources ----\n",
    "    peak_alloc, peak_reserved, gpu_used, sys_used = log_memory()\n",
    "\n",
    "    mse_l_ngd.append(mse)\n",
    "    time_l_ngd.append(elapsed)\n",
    "    vram_l_ngd.append(peak_alloc)\n",
    "    ram_l_ngd.append(delta_ram)\n",
    "\n",
    "    print(f\"SVGP-NGD Rep {rep + 1}: MSE={mse:.4f}, Time={elapsed:.2f}s, RAM Î”={delta_ram:.2f}MB, VRAM={peak_alloc:.2f}MB\")\n",
    "\n",
    "    # ---- Cleanup ----\n",
    "    del model, likelihood\n",
    "    gc.collect()\n",
    "    if gpu:\n",
    "        torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb44415b-9236-403d-ab39-c8e3fbfa28bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(statistics.mean(mse_l_ngd[1:]))\n",
    "print(statistics.stdev(mse_l_ngd[1:]))\n",
    "\n",
    "print(statistics.mean(time_l_ngd[1:]))\n",
    "print(statistics.stdev(time_l_ngd[1:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b8e294-2c10-447c-b1dd-41f6a4ea12f9",
   "metadata": {},
   "source": [
    "# VNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb87cd68-1d06-41cf-9e3b-4eb7a992502b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VNN\n",
    "max_vram = 0\n",
    "gc.collect()\n",
    "if gpu:\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0856a26a-5d71-4a08-9f5c-91ed27786be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import gc\n",
    "import time\n",
    "import statistics\n",
    "import torch\n",
    "import gpytorch\n",
    "import faiss\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import tqdm\n",
    "from gpytorch.models import ApproximateGP\n",
    "from gpytorch.variational.nearest_neighbor_variational_strategy import NNVariationalStrategy\n",
    "class GPModel(ApproximateGP):\n",
    "    def __init__(self, inducing_points, likelihood, k=256, training_batch_size=256):\n",
    "        m, d = inducing_points.shape\n",
    "        self.m = m\n",
    "        self.k = k\n",
    "        variational_distribution = gpytorch.variational.MeanFieldVariationalDistribution(m)\n",
    "        if gpu:\n",
    "            inducing_points = inducing_points.cuda()\n",
    "        variational_strategy = NNVariationalStrategy(\n",
    "            self, inducing_points, variational_distribution,\n",
    "            k=k, training_batch_size=training_batch_size\n",
    "        )\n",
    "        super(GPModel, self).__init__(variational_strategy)\n",
    "        self.mean_module = gpytorch.means.ZeroMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(\n",
    "            gpytorch.kernels.MaternKernel(nu=1.5, ard_num_dims=d)\n",
    "        )\n",
    "        self.likelihood = likelihood\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        vram_usage()  # assumed to be defined elsewhere\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "    def __call__(self, x, prior=False, **kwargs):\n",
    "        if x is not None:\n",
    "            if x.dim() == 1:\n",
    "                x = x.unsqueeze(-1)\n",
    "        return self.variational_strategy(x=x, prior=False, **kwargs)\n",
    "\n",
    "\n",
    "n_replicates = 11\n",
    "num_epochs = 10#30\n",
    "random_state = 42\n",
    "gpu = torch.cuda.is_available()\n",
    "\n",
    "if False:\n",
    "    k = 32\n",
    "    training_batch_size = 32\n",
    "else:\n",
    "    k = 160#320\n",
    "    training_batch_size = 320 * 4\n",
    "\n",
    "mse_l_vnn = []\n",
    "time_l_vnn = []\n",
    "vram_l_vnn = []\n",
    "ram_l_vnn = []\n",
    "\n",
    "\n",
    "for rep in range(n_replicates):\n",
    "    print(f\"\\n=== Replicate {rep + 1}/{n_replicates} ===\")\n",
    "\n",
    "    train_x, train_y, test_x, test_y = splitter(\n",
    "        all_x, all_y,\n",
    "        n_train=400000, n_test=20000,\n",
    "        random_state=random_state + rep,\n",
    "        move_to_gpu=gpu\n",
    "    )\n",
    "\n",
    "    batch_size = 32\n",
    "    train_dataset = TensorDataset(train_x, train_y)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_dataset = TensorDataset(test_x, test_y)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "    mem_begin = psutil.virtual_memory().used / (1024 ** 2)\n",
    "    likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "    model = GPModel(\n",
    "        inducing_points=train_x[::1].contiguous(),\n",
    "        likelihood=likelihood,\n",
    "        k=k,\n",
    "        training_batch_size=training_batch_size\n",
    "    )\n",
    "\n",
    "    if gpu:\n",
    "        likelihood = likelihood.cuda()\n",
    "        model = model.cuda()\n",
    "\n",
    "    num_batches = model.variational_strategy._total_training_batches\n",
    "\n",
    "    model.train()\n",
    "    likelihood.train()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.02)\n",
    "    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "    start = time.time()\n",
    "    epochs_iter = tqdm.tqdm(range(num_epochs), desc=f\"Epoch {rep + 1}\")\n",
    "    for epoch in epochs_iter:\n",
    "        minibatch_iter = tqdm.tqdm(range(num_batches), leave=False, position=0)\n",
    "        for batch_idx in minibatch_iter:\n",
    "            optimizer.zero_grad()\n",
    "            output = model(x=None)\n",
    "            current_indices = model.variational_strategy.current_training_indices\n",
    "            y_batch = train_y[..., current_indices]\n",
    "            if gpu:\n",
    "                y_batch = y_batch.cuda()\n",
    "            loss = -mll(output, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            minibatch_iter.set_postfix(loss=loss.item())\n",
    "    elapsed = time.time() - start\n",
    "\n",
    "\n",
    "    mem_end = psutil.virtual_memory().used / (1024 ** 2)\n",
    "    delta_ram = mem_end - mem_begin\n",
    "\n",
    "    model.eval()\n",
    "    likelihood.eval()\n",
    "    means = torch.tensor([0.])\n",
    "    with torch.no_grad():\n",
    "        for x_batch, _ in test_loader:\n",
    "            preds = model(x_batch)\n",
    "            means = torch.cat([means, preds.mean.cpu()])\n",
    "    means = means[1:]\n",
    "    mse = torch.mean((means - test_y.cpu()) ** 2).item()\n",
    "\n",
    "    peak_alloc, peak_reserved, gpu_used, sys_used = log_memory()\n",
    "    mse_l_vnn.append(mse)\n",
    "    time_l_vnn.append(elapsed)\n",
    "    vram_l_vnn.append(peak_alloc)\n",
    "    ram_l_vnn.append(delta_ram)\n",
    "\n",
    "    print(f\"VNN Rep {rep + 1}: MSE={mse:.4f}, Time={elapsed:.2f}s, RAM Î”={delta_ram:.2f}MB, VRAM={peak_alloc:.2f}MB\")\n",
    "    del model, likelihood\n",
    "    gc.collect()\n",
    "    if gpu:\n",
    "        torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887db61e-ec92-4906-bfe3-2352d74479d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(statistics.mean(mse_l_vnn[1:]))\n",
    "print(statistics.stdev(mse_l_vnn[1:]))\n",
    "\n",
    "print(statistics.mean(time_l_vnn[1:]))\n",
    "print(statistics.stdev(time_l_vnn[1:]))\n",
    "\n",
    "print(\"VNN     --- MSE:\", round(statistics.mean(mse_l_vnn[1:]), 4), \"(\", round(statistics.stdev(mse_l_vnn[1:]), 4), \")  Time:\", round(statistics.mean(time_l_vnn[1:]), 4), \"(\", round(statistics.stdev(time_l_vnn[1:]), 4), \")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af2777a-12b2-4376-8511-e9ff2af69a6e",
   "metadata": {},
   "source": [
    "# Compile Table (MSE and Time only)\n",
    "Order:\n",
    "SKI\n",
    "SGPR\n",
    "LOVE\n",
    "DKL\n",
    "SVGP-CI\n",
    "SVGP\n",
    "NGD\n",
    "VNN\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddbd90b-6fdf-48d9-a45a-ff205754ee6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SKI     --- MSE:\", statistics.mean(mse_l_ski[1:]), \"(\", statistics.stdev(mse_l_ski[1:]), \")  Time:\", statistics.mean(time_l_ski[1:]), \"(\", statistics.stdev(time_l_ski[1:]), \")\")\n",
    "print(\"SGPR    --- MSE:\", statistics.mean(mse_l_sgpr[1:]), \"(\", statistics.stdev(mse_l_sgpr[1:]), \")  Time:\", statistics.mean(time_l_sgpr[1:]), \"(\", statistics.stdev(time_l_sgpr[1:]), \")\")\n",
    "print(\"LOVE    --- MSE:\", statistics.mean(mse_l_love[1:]), \"(\", statistics.stdev(mse_l_love[1:]), \")  Time:\", statistics.mean(time_l_love[1:]), \"(\", statistics.stdev(time_l_love[1:]), \")\")\n",
    "print(\"DKL     --- MSE:\", statistics.mean(mse_l_dkl[1:]), \"(\", statistics.stdev(mse_l_dkl[1:]), \")  Time:\", statistics.mean(time_l_dkl[1:]), \"(\", statistics.stdev(time_l_dkl[1:]), \")\")\n",
    "print(\"SVGP-CI --- MSE:\", statistics.mean(mse_l_svgpci[1:]), \"(\", statistics.stdev(mse_l_svgpci[1:]), \")  Time:\", statistics.mean(time_l_svgpci[1:]), \"(\", statistics.stdev(time_l_svgpci[1:]), \")\")\n",
    "print(\"SVGP    --- MSE:\", statistics.mean(mse_l_svgp[1:]), \"(\", statistics.stdev(mse_l_svgp[1:]), \")  Time:\", statistics.mean(time_l_svgp[1:]), \"(\", statistics.stdev(time_l_svgp[1:]), \")\")\n",
    "print(\"NGD     --- MSE:\", statistics.mean(mse_l_ngd[1:]), \"(\", statistics.stdev(mse_l_ngd[1:]), \")  Time:\", statistics.mean(time_l_ngd[1:]), \"(\", statistics.stdev(time_l_ngd[1:]), \")\")\n",
    "print(\"VNN     --- MSE:\", statistics.mean(mse_l_vnn[1:]), \"(\", statistics.stdev(mse_l_vnn[1:]), \")  Time:\", statistics.mean(time_l_vnn[1:]), \"(\", statistics.stdev(time_l_vnn[1:]), \")\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86ecab9-b529-4142-af05-eede13567719",
   "metadata": {},
   "source": [
    "Reordering to match the table in the paper:\n",
    "SVGP\n",
    "SVGP-CI\n",
    "VNN\n",
    "NGD\n",
    "DKL\n",
    "SGPR\n",
    "SKI\n",
    "LOVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713418b4-3d7c-4b1a-92ac-a6d31d0ddec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SVGP    --- MSE:\", statistics.mean(mse_l_svgp[1:]), \"(\", statistics.stdev(mse_l_svgp[1:]), \")  Time:\", statistics.mean(time_l_svgp[1:]), \"(\", statistics.stdev(time_l_svgp[1:]), \")\")\n",
    "print(\"SVGP-CI --- MSE:\", statistics.mean(mse_l_svgpci[1:]), \"(\", statistics.stdev(mse_l_svgpci[1:]), \")  Time:\", statistics.mean(time_l_svgpci[1:]), \"(\", statistics.stdev(time_l_svgpci[1:]), \")\")\n",
    "print(\"VNN     --- MSE:\", statistics.mean(mse_l_vnn[1:]), \"(\", statistics.stdev(mse_l_vnn[1:]), \")  Time:\", statistics.mean(time_l_vnn[1:]), \"(\", statistics.stdev(time_l_vnn[1:]), \")\")\n",
    "print(\"NGD     --- MSE:\", statistics.mean(mse_l_ngd[1:]), \"(\", statistics.stdev(mse_l_ngd[1:]), \")  Time:\", statistics.mean(time_l_ngd[1:]), \"(\", statistics.stdev(time_l_ngd[1:]), \")\")\n",
    "print(\"DKL     --- MSE:\", statistics.mean(mse_l_dkl[1:]), \"(\", statistics.stdev(mse_l_dkl[1:]), \")  Time:\", statistics.mean(time_l_dkl[1:]), \"(\", statistics.stdev(time_l_dkl[1:]), \")\")\n",
    "print(\"SGPR    --- MSE:\", statistics.mean(mse_l_sgpr[1:]), \"(\", statistics.stdev(mse_l_sgpr[1:]), \")  Time:\", statistics.mean(time_l_sgpr[1:]), \"(\", statistics.stdev(time_l_sgpr[1:]), \")\")\n",
    "print(\"SKI     --- MSE:\", statistics.mean(mse_l_ski[1:]), \"(\", statistics.stdev(mse_l_ski[1:]), \")  Time:\", statistics.mean(time_l_ski[1:]), \"(\", statistics.stdev(time_l_ski[1:]), \")\")\n",
    "print(\"LOVE    --- MSE:\", statistics.mean(mse_l_love[1:]), \"(\", statistics.stdev(mse_l_love[1:]), \")  Time:\", statistics.mean(time_l_love[1:]), \"(\", statistics.stdev(time_l_love[1:]), \")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b53ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SVGP    --- MSE:\", round(statistics.mean(mse_l_svgp[1:]), 4), \"(\", round(statistics.stdev(mse_l_svgp[1:]), 4), \")  Time:\", round(statistics.mean(time_l_svgp[1:]), 4), \"(\", round(statistics.stdev(time_l_svgp[1:]), 4), \")\")\n",
    "print(\"SVGP-CI --- MSE:\", round(statistics.mean(mse_l_svgpci[1:]), 4), \"(\", round(statistics.stdev(mse_l_svgpci[1:]), 4), \")  Time:\", round(statistics.mean(time_l_svgpci[1:]), 4), \"(\", round(statistics.stdev(time_l_svgpci[1:]), 4), \")\")\n",
    "#print(\"VNN     --- MSE:\", round(statistics.mean(mse_l_vnn[1:]), 4), \"(\", round(statistics.stdev(mse_l_vnn[1:]), 4), \")  Time:\", round(statistics.mean(time_l_vnn[1:]), 4), \"(\", round(statistics.stdev(time_l_vnn[1:]), 4), \")\")\n",
    "print(\"NGD     --- MSE:\", round(statistics.mean(mse_l_ngd[1:]), 4), \"(\", round(statistics.stdev(mse_l_ngd[1:]), 4), \")  Time:\", round(statistics.mean(time_l_ngd[1:]), 4), \"(\", round(statistics.stdev(time_l_ngd[1:]), 4), \")\")\n",
    "print(\"DKL     --- MSE:\", round(statistics.mean(mse_l_dkl[1:]), 4), \"(\", round(statistics.stdev(mse_l_dkl[1:]), 4), \")  Time:\", round(statistics.mean(time_l_dkl[1:]), 4), \"(\", round(statistics.stdev(time_l_dkl[1:]), 4), \")\")\n",
    "print(\"SGPR    --- MSE:\", round(statistics.mean(mse_l_sgpr[1:]), 4), \"(\", round(statistics.stdev(mse_l_sgpr[1:]), 4), \")  Time:\", round(statistics.mean(time_l_sgpr[1:]), 4), \"(\", round(statistics.stdev(time_l_sgpr[1:]), 4), \")\")\n",
    "print(\"SKI     --- MSE:\", round(statistics.mean(mse_l_ski[1:]), 4), \"(\", round(statistics.stdev(mse_l_ski[1:]), 4), \")  Time:\", round(statistics.mean(time_l_ski[1:]), 4), \"(\", round(statistics.stdev(time_l_ski[1:]), 4), \")\")\n",
    "print(\"LOVE    --- MSE:\", round(statistics.mean(mse_l_love[1:]), 4), \"(\", round(statistics.stdev(mse_l_love[1:]), 4), \")  Time:\", round(statistics.mean(time_l_love[1:]), 4), \"(\", round(statistics.stdev(time_l_love[1:]), 4), \")\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f90b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "\n",
    "\n",
    "methods = [\n",
    "    (\"SVGP\",   mse_l_svgp,   time_l_svgp),\n",
    "    (\"SVGP-CI\",mse_l_svgpci, time_l_svgpci),\n",
    "    (\"NGD\",    mse_l_ngd,    time_l_ngd),\n",
    "    (\"DKL\",    mse_l_dkl,    time_l_dkl),\n",
    "    (\"SGPR\",   mse_l_sgpr,   time_l_sgpr),\n",
    "    (\"SKI\",    mse_l_ski,    time_l_ski),\n",
    "    (\"LOVE\",   mse_l_love,   time_l_love),\n",
    "]\n",
    "\n",
    "for name, mse_list, time_list in methods:\n",
    "    data_mse  = mse_list[1:]\n",
    "    data_time = time_list[1:]\n",
    "    mean_mse  = statistics.mean(data_mse)\n",
    "    sd_mse    = statistics.stdev(data_mse)\n",
    "    mean_time = statistics.mean(data_time)\n",
    "    sd_time   = statistics.stdev(data_time)\n",
    "    print(f\"{name:<8} & {mean_mse:.4f}  & ({sd_mse:.4f} )  & {mean_time:.4f}  & ({sd_time:.4f} )\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scaleGP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
